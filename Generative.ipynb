{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version is  2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa as li\n",
    "import time\n",
    "\n",
    "from IPython import display\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"TensorFlow version is \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "F:\\TF\\AudioRec\\AudioData\\5 Мира\\1 Мира\\1.wav\n",
      "F:\\TF\\AudioRec\\AudioData\\5 Мира\\1 Мира\\10.wav\n",
      "F:\\TF\\AudioRec\\AudioData\\5 Мира\\1 Мира\\11.wav\n",
      "F:\\TF\\AudioRec\\AudioData\\5 Мира\\1 Мира\\12.wav\n",
      "F:\\TF\\AudioRec\\AudioData\\5 Мира\\1 Мира\\13.wav\n",
      "F:\\TF\\AudioRec\\AudioData\\5 Мира\\1 Мира\\14.wav\n",
      "F:\\TF\\AudioRec\\AudioData\\5 Мира\\1 Мира\\15.wav\n",
      "F:\\TF\\AudioRec\\AudioData\\5 Мира\\1 Мира\\16.wav\n",
      "F:\\TF\\AudioRec\\AudioData\\5 Мира\\1 Мира\\17.wav\n",
      "F:\\TF\\AudioRec\\AudioData\\5 Мира\\1 Мира\\18.wav\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_MIRA = 'AudioData/5 Мира'\n",
    "\n",
    "paths = li.util.find_files(PATH_TO_MIRA)\n",
    "print(len(paths))\n",
    "print('\\n'.join(paths[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(path, sr=16000):\n",
    "    example = li.load(path, sr=sr)[0]\n",
    "    if example.size < sr:\n",
    "        example = np.concatenate((example, np.zeros(sr-example.size)))\n",
    "    else:\n",
    "        example = example[:sr]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(paths, num_threads=4):\n",
    "    with ThreadPoolExecutor(num_threads) as pool:\n",
    "        data = list(pool.map(get_audio, paths))\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (None, 16000), types: tf.float64>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 10\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(data).shuffle(70).batch(BATCH_SIZE)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 16000, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 16000, 10)         40        \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 4000, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1000, 1)           40        \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1000, 1)           4         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1000, 1)           0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 100)               30900     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 31,085\n",
      "Trainable params: 31,083\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer((16000)),\n",
    "    tf.keras.layers.Reshape((16000, 1)),\n",
    "    tf.keras.layers.Conv1D(filters=10, kernel_size=4, strides=1, padding='same', use_bias=False),\n",
    "    tf.keras.layers.MaxPool1D(4),\n",
    "    tf.keras.layers.Conv1D(filters=1, kernel_size=4, strides=4, use_bias=False),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('tanh'),\n",
    "    tf.keras.layers.GRU(100),\n",
    "    tf.keras.layers.Dense(1)\n",
    "], name='discriminator')\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 100)               30900     \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose (Conv1DTran (None, 400, 1)            4         \n",
      "_________________________________________________________________\n",
      "p_re_lu (PReLU)              (None, 400, 1)            400       \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_1 (Conv1DTr (None, 400, 10)           20        \n",
      "_________________________________________________________________\n",
      "p_re_lu_1 (PReLU)            (None, 400, 10)           4000      \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_2 (Conv1DTr (None, 1600, 20)          800       \n",
      "_________________________________________________________________\n",
      "p_re_lu_2 (PReLU)            (None, 1600, 20)          32000     \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_3 (Conv1DTr (None, 16000, 1)          200       \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 1)          0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 16000)             0         \n",
      "=================================================================\n",
      "Total params: 68,324\n",
      "Trainable params: 68,324\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer((100,)),\n",
    "    tf.keras.layers.Reshape((100, 1)),\n",
    "    tf.keras.layers.GRU(100),\n",
    "    tf.keras.layers.Reshape((100, 1)),\n",
    "    tf.keras.layers.Conv1DTranspose(filters=1, kernel_size=4, strides=4, use_bias=False),\n",
    "    tf.keras.layers.PReLU(),\n",
    "    tf.keras.layers.Conv1DTranspose(filters=10, kernel_size=2, strides=1, padding='same', use_bias=False),\n",
    "    tf.keras.layers.PReLU(),\n",
    "    tf.keras.layers.Conv1DTranspose(filters=20, kernel_size=4, strides=4, padding='same', use_bias=False),\n",
    "    tf.keras.layers.PReLU(),\n",
    "    tf.keras.layers.Conv1DTranspose(filters=1, kernel_size=10, strides=10, padding='same', use_bias=False),\n",
    "    tf.keras.layers.Activation('tanh'),\n",
    "    tf.keras.layers.Reshape((16000,))\n",
    "], name='generator')\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "noise = tf.random.normal((10, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 16000])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = generator(noise)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = loss(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = loss(tf.zeros_like(fake_output), fake_output)\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return loss(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_optim = tf.keras.optimizers.Adam(1e-4)\n",
    "disc_optim = tf.keras.optimizers.Adam(1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(train_batch):\n",
    "    noise = tf.random.normal([BATCH_SIZE, latent_dim])\n",
    "    \n",
    "    with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
    "        generated_audio = generator(noise, training=True)\n",
    "        \n",
    "        real_output = discriminator(train_batch, training=True)\n",
    "        fake_output = discriminator(generated_audio, training=True)\n",
    "        \n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "        \n",
    "    gen_grad = g_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    disc_grad = d_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    \n",
    "    gen_optim.apply_gradients(zip(gen_grad, generator.trainable_variables))\n",
    "    disc_optim.apply_gradients(zip(disc_grad, discriminator.trainable_variables))\n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    start = time.time()\n",
    "    for i in range(epochs):\n",
    "        for train_batch in dataset:\n",
    "            gen_loss, disc_loss = train_step(train_batch)\n",
    "            \n",
    "        if (i+1) % 10 == 0:\n",
    "            print('Epoch {:4d}: gen_loss - {:.4f} | disc_loss - {:.4f} | {:.3f} seconds'.format(\n",
    "                i+1, gen_loss, disc_loss, time.time()-start))\n",
    "            start = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   10: gen_loss - 0.9212 | disc_loss - 0.8397 | 105.931 seconds\n",
      "Epoch   20: gen_loss - 0.8976 | disc_loss - 1.1661 | 106.088 seconds\n",
      "Epoch   30: gen_loss - 0.8757 | disc_loss - 0.7885 | 107.026 seconds\n",
      "Epoch   40: gen_loss - 0.8429 | disc_loss - 0.8709 | 107.400 seconds\n",
      "Epoch   50: gen_loss - 0.8206 | disc_loss - 1.3100 | 109.457 seconds\n",
      "Epoch   60: gen_loss - 0.8074 | disc_loss - 1.0489 | 106.698 seconds\n",
      "Epoch   70: gen_loss - 0.8162 | disc_loss - 1.4165 | 101.400 seconds\n",
      "Epoch   80: gen_loss - 0.8649 | disc_loss - 1.4502 | 104.529 seconds\n",
      "Epoch   90: gen_loss - 0.8916 | disc_loss - 1.4709 | 108.202 seconds\n",
      "Epoch  100: gen_loss - 0.9470 | disc_loss - 0.9431 | 108.662 seconds\n",
      "Epoch  110: gen_loss - 1.0020 | disc_loss - 1.2159 | 106.809 seconds\n",
      "Epoch  120: gen_loss - 1.0288 | disc_loss - 1.4992 | 107.864 seconds\n",
      "Epoch  130: gen_loss - 1.0364 | disc_loss - 0.8872 | 107.989 seconds\n",
      "Epoch  140: gen_loss - 1.0386 | disc_loss - 1.4843 | 108.945 seconds\n",
      "Epoch  150: gen_loss - 1.0469 | disc_loss - 1.3732 | 108.608 seconds\n",
      "Epoch  160: gen_loss - 1.0162 | disc_loss - 0.6810 | 104.910 seconds\n",
      "Epoch  170: gen_loss - 0.9851 | disc_loss - 1.0689 | 107.326 seconds\n",
      "Epoch  180: gen_loss - 0.9454 | disc_loss - 1.4806 | 117.555 seconds\n",
      "Epoch  190: gen_loss - 0.9227 | disc_loss - 0.9029 | 145.743 seconds\n",
      "Epoch  200: gen_loss - 0.8653 | disc_loss - 1.4009 | 145.067 seconds\n",
      "Epoch  210: gen_loss - 0.8257 | disc_loss - 0.7823 | 145.008 seconds\n",
      "Epoch  220: gen_loss - 0.8115 | disc_loss - 1.3151 | 145.322 seconds\n",
      "Epoch  230: gen_loss - 0.8379 | disc_loss - 1.4135 | 145.218 seconds\n",
      "Epoch  240: gen_loss - 0.8973 | disc_loss - 1.4461 | 145.235 seconds\n",
      "Epoch  250: gen_loss - 0.9255 | disc_loss - 1.4393 | 146.107 seconds\n",
      "Epoch  260: gen_loss - 0.9396 | disc_loss - 1.4166 | 145.759 seconds\n",
      "Epoch  270: gen_loss - 0.1217 | disc_loss - 3.0805 | 145.332 seconds\n",
      "Epoch  280: gen_loss - 0.6199 | disc_loss - 1.5310 | 144.813 seconds\n",
      "Epoch  290: gen_loss - 0.7272 | disc_loss - 1.4208 | 141.831 seconds\n",
      "Epoch  300: gen_loss - 0.7898 | disc_loss - 1.3634 | 117.908 seconds\n",
      "Epoch  310: gen_loss - 0.8293 | disc_loss - 1.3513 | 132.150 seconds\n",
      "Epoch  320: gen_loss - 0.7679 | disc_loss - 1.3892 | 130.719 seconds\n",
      "Epoch  330: gen_loss - 0.7102 | disc_loss - 1.4187 | 141.579 seconds\n",
      "Epoch  340: gen_loss - 0.6831 | disc_loss - 1.4525 | 145.721 seconds\n",
      "Epoch  350: gen_loss - 0.6849 | disc_loss - 1.4610 | 145.134 seconds\n",
      "Epoch  360: gen_loss - 0.7153 | disc_loss - 1.4122 | 141.541 seconds\n",
      "Epoch  370: gen_loss - 0.7577 | disc_loss - 1.3630 | 141.359 seconds\n",
      "Epoch  380: gen_loss - 0.7858 | disc_loss - 1.3208 | 141.806 seconds\n",
      "Epoch  390: gen_loss - 0.7696 | disc_loss - 1.3056 | 140.863 seconds\n",
      "Epoch  400: gen_loss - 0.7040 | disc_loss - 1.3754 | 144.942 seconds\n",
      "Epoch  410: gen_loss - 0.6560 | disc_loss - 1.4395 | 145.881 seconds\n",
      "Epoch  420: gen_loss - 0.6604 | disc_loss - 1.4374 | 145.497 seconds\n",
      "Epoch  430: gen_loss - 0.6904 | disc_loss - 1.4092 | 145.182 seconds\n",
      "Epoch  440: gen_loss - 0.7304 | disc_loss - 1.3678 | 144.184 seconds\n",
      "Epoch  450: gen_loss - 0.7672 | disc_loss - 1.3353 | 144.531 seconds\n",
      "Epoch  460: gen_loss - 0.7830 | disc_loss - 1.3468 | 144.979 seconds\n",
      "Epoch  470: gen_loss - 0.7437 | disc_loss - 1.3569 | 144.722 seconds\n",
      "Epoch  480: gen_loss - 0.6597 | disc_loss - 1.4161 | 144.058 seconds\n",
      "Epoch  490: gen_loss - 0.6257 | disc_loss - 1.4490 | 145.647 seconds\n",
      "Epoch  500: gen_loss - 0.6649 | disc_loss - 1.4342 | 145.088 seconds\n",
      "Epoch  510: gen_loss - 0.7263 | disc_loss - 1.3667 | 145.563 seconds\n",
      "Epoch  520: gen_loss - 0.7546 | disc_loss - 1.3176 | 145.450 seconds\n",
      "Epoch  530: gen_loss - 0.7241 | disc_loss - 1.3516 | 145.037 seconds\n",
      "Epoch  540: gen_loss - 0.6387 | disc_loss - 1.4762 | 144.040 seconds\n",
      "Epoch  550: gen_loss - 0.6921 | disc_loss - 1.4065 | 145.621 seconds\n",
      "Epoch  560: gen_loss - 0.7548 | disc_loss - 1.3447 | 145.817 seconds\n",
      "Epoch  570: gen_loss - 0.7619 | disc_loss - 1.3430 | 145.849 seconds\n",
      "Epoch  580: gen_loss - 0.6587 | disc_loss - 1.4165 | 119.125 seconds\n",
      "Epoch  590: gen_loss - 0.6734 | disc_loss - 1.4093 | 132.285 seconds\n",
      "Epoch  600: gen_loss - 0.7380 | disc_loss - 1.3652 | 143.807 seconds\n",
      "Epoch  610: gen_loss - 0.7731 | disc_loss - 1.3528 | 144.991 seconds\n",
      "Epoch  620: gen_loss - 0.6924 | disc_loss - 1.3932 | 145.022 seconds\n",
      "Epoch  630: gen_loss - 0.7087 | disc_loss - 1.3878 | 144.557 seconds\n",
      "Epoch  640: gen_loss - 0.7308 | disc_loss - 1.3612 | 144.583 seconds\n",
      "Epoch  650: gen_loss - 0.6921 | disc_loss - 1.3846 | 144.736 seconds\n",
      "Epoch  660: gen_loss - 0.6845 | disc_loss - 1.4055 | 142.479 seconds\n",
      "Epoch  670: gen_loss - 0.7164 | disc_loss - 1.3771 | 143.440 seconds\n",
      "Epoch  680: gen_loss - 0.7029 | disc_loss - 1.4017 | 144.384 seconds\n",
      "Epoch  690: gen_loss - 0.6950 | disc_loss - 1.3941 | 144.057 seconds\n",
      "Epoch  700: gen_loss - 0.6954 | disc_loss - 1.3850 | 144.350 seconds\n",
      "Epoch  710: gen_loss - 0.6843 | disc_loss - 1.3900 | 144.001 seconds\n",
      "Epoch  720: gen_loss - 0.6938 | disc_loss - 1.3834 | 144.798 seconds\n",
      "Epoch  730: gen_loss - 0.6930 | disc_loss - 1.3926 | 145.006 seconds\n",
      "Epoch  740: gen_loss - 0.6890 | disc_loss - 1.3896 | 144.061 seconds\n",
      "Epoch  750: gen_loss - 0.6880 | disc_loss - 1.3876 | 144.399 seconds\n",
      "Epoch  760: gen_loss - 0.6870 | disc_loss - 1.3896 | 140.947 seconds\n",
      "Epoch  770: gen_loss - 0.6915 | disc_loss - 1.3873 | 140.006 seconds\n",
      "Epoch  780: gen_loss - 0.6945 | disc_loss - 1.3886 | 140.346 seconds\n",
      "Epoch  790: gen_loss - 0.6987 | disc_loss - 1.3935 | 139.498 seconds\n",
      "Epoch  800: gen_loss - 0.7018 | disc_loss - 1.3852 | 141.182 seconds\n",
      "Epoch  810: gen_loss - 0.7026 | disc_loss - 1.3873 | 144.744 seconds\n",
      "Epoch  820: gen_loss - 0.7008 | disc_loss - 1.3870 | 144.886 seconds\n",
      "Epoch  830: gen_loss - 0.6972 | disc_loss - 1.3892 | 144.962 seconds\n",
      "Epoch  840: gen_loss - 0.6941 | disc_loss - 1.3913 | 145.223 seconds\n",
      "Epoch  850: gen_loss - 0.6915 | disc_loss - 1.3873 | 144.398 seconds\n",
      "Epoch  860: gen_loss - 0.6898 | disc_loss - 1.3853 | 144.147 seconds\n",
      "Epoch  870: gen_loss - 0.6882 | disc_loss - 1.3851 | 144.658 seconds\n",
      "Epoch  880: gen_loss - 0.6873 | disc_loss - 1.3838 | 144.295 seconds\n",
      "Epoch  890: gen_loss - 0.6880 | disc_loss - 1.3862 | 124.049 seconds\n",
      "Epoch  900: gen_loss - 0.6895 | disc_loss - 1.3907 | 104.520 seconds\n",
      "Epoch  910: gen_loss - 0.6936 | disc_loss - 1.3854 | 105.318 seconds\n",
      "Epoch  920: gen_loss - 0.6989 | disc_loss - 1.3854 | 108.207 seconds\n",
      "Epoch  930: gen_loss - 0.7009 | disc_loss - 1.3844 | 108.672 seconds\n",
      "Epoch  940: gen_loss - 0.6994 | disc_loss - 1.3858 | 105.401 seconds\n",
      "Epoch  950: gen_loss - 0.6973 | disc_loss - 1.3855 | 104.263 seconds\n",
      "Epoch  960: gen_loss - 0.6930 | disc_loss - 1.3907 | 104.403 seconds\n",
      "Epoch  970: gen_loss - 0.6905 | disc_loss - 1.3859 | 103.722 seconds\n",
      "Epoch  980: gen_loss - 0.6899 | disc_loss - 1.3832 | 111.600 seconds\n",
      "Epoch  990: gen_loss - 0.6879 | disc_loss - 1.3857 | 145.500 seconds\n",
      "Epoch 1000: gen_loss - 0.6891 | disc_loss - 1.3892 | 145.390 seconds\n"
     ]
    }
   ],
   "source": [
    "train(train_dataset, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save(\"models/generator-v0.1.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audiorec",
   "language": "python",
   "name": "audiorec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
