{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TensorFlow version is  2.3.1\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import librosa as li\n",
    "import time\n",
    "\n",
    "from IPython import display\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(\"TensorFlow version is \", tf.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "70\n",
      "F:\\TF\\AudioRec\\AudioData\\5 Мира\\1 Мира\\1.wav\n",
      "F:\\TF\\AudioRec\\AudioData\\5 Мира\\1 Мира\\10.wav\n",
      "F:\\TF\\AudioRec\\AudioData\\5 Мира\\1 Мира\\11.wav\n",
      "F:\\TF\\AudioRec\\AudioData\\5 Мира\\1 Мира\\12.wav\n",
      "F:\\TF\\AudioRec\\AudioData\\5 Мира\\1 Мира\\13.wav\n",
      "F:\\TF\\AudioRec\\AudioData\\5 Мира\\1 Мира\\14.wav\n",
      "F:\\TF\\AudioRec\\AudioData\\5 Мира\\1 Мира\\15.wav\n",
      "F:\\TF\\AudioRec\\AudioData\\5 Мира\\1 Мира\\16.wav\n",
      "F:\\TF\\AudioRec\\AudioData\\5 Мира\\1 Мира\\17.wav\n",
      "F:\\TF\\AudioRec\\AudioData\\5 Мира\\1 Мира\\18.wav\n"
     ]
    }
   ],
   "source": [
    "PATH_TO_MIRA = 'AudioData/5 Мира'\n",
    "\n",
    "paths = li.util.find_files(PATH_TO_MIRA)\n",
    "print(len(paths))\n",
    "print('\\n'.join(paths[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(path, sr=16000):\n",
    "    example = li.load(path, sr=sr)[0]\n",
    "    if example.size < sr:\n",
    "        example = np.concatenate((example, np.zeros(sr-example.size)))\n",
    "    else:\n",
    "        example = example[:sr]\n",
    "    return example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(paths, num_threads=4):\n",
    "    with ThreadPoolExecutor(num_threads) as pool:\n",
    "        data = list(pool.map(get_audio, paths))\n",
    "    return np.array(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = get_data(paths, 32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: (None, 16000), types: tf.float64>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 14\n",
    "\n",
    "train_dataset = tf.data.Dataset.from_tensor_slices(data).shuffle(70).batch(BATCH_SIZE)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"discriminator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape (Reshape)            (None, 16000, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv1d (Conv1D)              (None, 16000, 10)         40        \n",
      "_________________________________________________________________\n",
      "max_pooling1d (MaxPooling1D) (None, 4000, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_1 (Conv1D)            (None, 1000, 1)           40        \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 1000, 1)           4         \n",
      "_________________________________________________________________\n",
      "activation (Activation)      (None, 1000, 1)           0         \n",
      "_________________________________________________________________\n",
      "gru (GRU)                    (None, 100)               30900     \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 101       \n",
      "=================================================================\n",
      "Total params: 31,085\n",
      "Trainable params: 31,083\n",
      "Non-trainable params: 2\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "discriminator = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer((16000)),\n",
    "    tf.keras.layers.Reshape((16000, 1)),\n",
    "    tf.keras.layers.Conv1D(filters=10, kernel_size=4, strides=1, padding='same', use_bias=False),\n",
    "    tf.keras.layers.MaxPool1D(4),\n",
    "    tf.keras.layers.Conv1D(filters=1, kernel_size=4, strides=4, use_bias=False),\n",
    "    tf.keras.layers.BatchNormalization(),\n",
    "    tf.keras.layers.Activation('tanh'),\n",
    "    tf.keras.layers.GRU(100),\n",
    "    tf.keras.layers.Dense(1)\n",
    "], name='discriminator')\n",
    "\n",
    "discriminator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"generator\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_1 (Reshape)          (None, 100, 1)            0         \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 100)               30900     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1000)              100000    \n",
      "_________________________________________________________________\n",
      "reshape_2 (Reshape)          (None, 1000, 1)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose (Conv1DTran (None, 1000, 1)           2         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_1 (Conv1DTr (None, 2000, 1)           2         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_2 (Conv1DTr (None, 4000, 1)           2         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_3 (Conv1DTr (None, 4000, 1)           1         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_4 (Conv1DTr (None, 8000, 1)           2         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_5 (Conv1DTr (None, 16000, 1)          2         \n",
      "_________________________________________________________________\n",
      "conv1d_transpose_6 (Conv1DTr (None, 16000, 1)          1         \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 16000, 1)          0         \n",
      "_________________________________________________________________\n",
      "reshape_3 (Reshape)          (None, 16000)             0         \n",
      "=================================================================\n",
      "Total params: 130,912\n",
      "Trainable params: 130,912\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "generator = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer((100,)),\n",
    "    tf.keras.layers.Reshape((100, 1)),\n",
    "    tf.keras.layers.GRU(100),\n",
    "    tf.keras.layers.Dense(1000, activation='relu', use_bias=False),\n",
    "    tf.keras.layers.Reshape((1000, 1)),\n",
    "    tf.keras.layers.Conv1DTranspose(filters=1, kernel_size=2, strides=1, padding='same', use_bias=False),\n",
    "    tf.keras.layers.Conv1DTranspose(filters=1, kernel_size=2, strides=2, padding='same', use_bias=False),\n",
    "    tf.keras.layers.Conv1DTranspose(filters=1, kernel_size=2, strides=2, padding='same', use_bias=False),\n",
    "    tf.keras.layers.Conv1DTranspose(filters=1, kernel_size=1, strides=1, padding='same', use_bias=False),\n",
    "    tf.keras.layers.Conv1DTranspose(filters=1, kernel_size=2, strides=2, padding='same', use_bias=False),\n",
    "    tf.keras.layers.Conv1DTranspose(filters=1, kernel_size=2, strides=2, padding='same', use_bias=False),\n",
    "    tf.keras.layers.Conv1DTranspose(filters=1, kernel_size=1, strides=1, padding='same', use_bias=False),\n",
    "    tf.keras.layers.Activation('tanh'),\n",
    "    tf.keras.layers.Reshape((16000,))\n",
    "], name='generator')\n",
    "\n",
    "generator.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 100\n",
    "noise = tf.random.normal((10, 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TensorShape([10, 16000])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test = generator(noise)\n",
    "test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = tf.keras.losses.BinaryCrossentropy(from_logits=True)\n",
    "\n",
    "def discriminator_loss(real_output, fake_output):\n",
    "    real_loss = loss(tf.ones_like(real_output), real_output)\n",
    "    fake_loss = loss(tf.zeros_like(fake_output), fake_output)\n",
    "    return real_loss + fake_loss\n",
    "\n",
    "def generator_loss(fake_output):\n",
    "    return loss(tf.ones_like(fake_output), fake_output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "gen_optim = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "disc_optim = tf.keras.optimizers.Adam(learning_rate=1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "@tf.function()\n",
    "def train_step(train_batch):\n",
    "    noise = tf.random.normal([BATCH_SIZE, latent_dim])\n",
    "    \n",
    "    with tf.GradientTape() as g_tape, tf.GradientTape() as d_tape:\n",
    "        generated_audio = generator(noise, training=True)\n",
    "        \n",
    "        real_output = discriminator(train_batch, training=True)\n",
    "        fake_output = discriminator(generated_audio, training=True)\n",
    "        \n",
    "        gen_loss = generator_loss(fake_output)\n",
    "        disc_loss = discriminator_loss(real_output, fake_output)\n",
    "        \n",
    "    gen_grad = g_tape.gradient(gen_loss, generator.trainable_variables)\n",
    "    disc_grad = d_tape.gradient(disc_loss, discriminator.trainable_variables)\n",
    "    \n",
    "    gen_optim.apply_gradients(zip(gen_grad, generator.trainable_variables))\n",
    "    disc_optim.apply_gradients(zip(disc_grad, discriminator.trainable_variables))\n",
    "    return gen_loss, disc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(dataset, epochs):\n",
    "    start = time.time()\n",
    "    for i in range(epochs):\n",
    "        for train_batch in dataset:\n",
    "            gen_loss, disc_loss = train_step(train_batch)\n",
    "            \n",
    "        if (i+1) % 10 == 0:\n",
    "            print('Epoch {:4d}: gen_loss - {:.4f} | disc_loss - {:.4f} | {:.3f} seconds'.format(\n",
    "                i+1, gen_loss, disc_loss, time.time()-start))\n",
    "            start = time.time()\n",
    "            \n",
    "        if gen_loss < 0.1 + 0.001:\n",
    "            break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch   10: gen_loss - 0.6979 | disc_loss - 1.3747 | 75.043 seconds\n",
      "Epoch   20: gen_loss - 0.7026 | disc_loss - 1.3578 | 73.003 seconds\n",
      "Epoch   30: gen_loss - 0.7247 | disc_loss - 0.6993 | 72.151 seconds\n",
      "Epoch   40: gen_loss - 2.1723 | disc_loss - 0.1230 | 72.721 seconds\n",
      "Epoch   50: gen_loss - 1.0021 | disc_loss - 0.4850 | 72.806 seconds\n",
      "Epoch   60: gen_loss - 1.1461 | disc_loss - 2.3429 | 72.669 seconds\n",
      "Epoch   70: gen_loss - 0.7464 | disc_loss - 1.5140 | 71.307 seconds\n",
      "Epoch   80: gen_loss - 0.5359 | disc_loss - 0.8827 | 72.817 seconds\n",
      "Epoch   90: gen_loss - 1.0254 | disc_loss - 0.4467 | 72.385 seconds\n",
      "Epoch  100: gen_loss - 1.8846 | disc_loss - 0.4117 | 71.409 seconds\n",
      "Epoch  110: gen_loss - 1.8517 | disc_loss - 0.1731 | 72.289 seconds\n",
      "Epoch  120: gen_loss - 2.6620 | disc_loss - 0.0745 | 72.202 seconds\n",
      "Epoch  130: gen_loss - 2.7928 | disc_loss - 0.0653 | 83.586 seconds\n",
      "Epoch  140: gen_loss - 3.0706 | disc_loss - 0.0495 | 102.068 seconds\n",
      "Epoch  150: gen_loss - 3.0964 | disc_loss - 0.5487 | 102.023 seconds\n",
      "Epoch  160: gen_loss - 3.1874 | disc_loss - 0.3038 | 82.848 seconds\n",
      "Epoch  170: gen_loss - 2.7704 | disc_loss - 1.6386 | 72.856 seconds\n",
      "Epoch  180: gen_loss - 1.7368 | disc_loss - 2.5839 | 73.123 seconds\n",
      "Epoch  190: gen_loss - 1.3599 | disc_loss - 2.3787 | 73.960 seconds\n",
      "Epoch  200: gen_loss - 1.1045 | disc_loss - 1.5633 | 71.758 seconds\n",
      "Epoch  210: gen_loss - 1.0335 | disc_loss - 1.5548 | 73.064 seconds\n",
      "Epoch  220: gen_loss - 0.8681 | disc_loss - 1.4135 | 73.186 seconds\n",
      "Epoch  230: gen_loss - 0.7718 | disc_loss - 1.3342 | 73.699 seconds\n",
      "Epoch  240: gen_loss - 0.7486 | disc_loss - 1.2122 | 75.762 seconds\n",
      "Epoch  250: gen_loss - 0.6786 | disc_loss - 1.1378 | 73.912 seconds\n",
      "Epoch  260: gen_loss - 0.7479 | disc_loss - 1.0397 | 71.141 seconds\n",
      "Epoch  270: gen_loss - 0.7383 | disc_loss - 0.8121 | 73.256 seconds\n",
      "Epoch  280: gen_loss - 0.8598 | disc_loss - 0.6669 | 74.936 seconds\n",
      "Epoch  290: gen_loss - 0.9335 | disc_loss - 1.2805 | 75.031 seconds\n",
      "Epoch  300: gen_loss - 1.0381 | disc_loss - 0.5170 | 75.608 seconds\n",
      "Epoch  310: gen_loss - 1.0588 | disc_loss - 0.5175 | 72.772 seconds\n",
      "Epoch  320: gen_loss - 1.1195 | disc_loss - 0.4628 | 73.304 seconds\n",
      "Epoch  330: gen_loss - 1.1247 | disc_loss - 0.4486 | 72.585 seconds\n",
      "Epoch  340: gen_loss - 1.2068 | disc_loss - 0.4041 | 100.861 seconds\n",
      "Epoch  350: gen_loss - 1.1559 | disc_loss - 0.4203 | 100.534 seconds\n",
      "Epoch  360: gen_loss - 1.4719 | disc_loss - 0.3964 | 101.345 seconds\n",
      "Epoch  370: gen_loss - 1.5471 | disc_loss - 0.2695 | 100.832 seconds\n",
      "Epoch  380: gen_loss - 0.6763 | disc_loss - 2.4908 | 100.734 seconds\n",
      "Epoch  390: gen_loss - 1.6387 | disc_loss - 0.4691 | 100.737 seconds\n",
      "Epoch  400: gen_loss - 1.5642 | disc_loss - 0.8969 | 100.494 seconds\n",
      "Epoch  410: gen_loss - 1.4903 | disc_loss - 0.6880 | 100.775 seconds\n",
      "Epoch  420: gen_loss - 1.4319 | disc_loss - 0.5918 | 100.377 seconds\n",
      "Epoch  430: gen_loss - 1.4552 | disc_loss - 0.2894 | 100.453 seconds\n",
      "Epoch  440: gen_loss - 1.4818 | disc_loss - 0.6894 | 100.846 seconds\n",
      "Epoch  450: gen_loss - 1.4874 | disc_loss - 0.4889 | 100.575 seconds\n",
      "Epoch  460: gen_loss - 1.5645 | disc_loss - 0.4781 | 100.481 seconds\n",
      "Epoch  470: gen_loss - 1.6584 | disc_loss - 0.2352 | 100.620 seconds\n",
      "Epoch  480: gen_loss - 0.7424 | disc_loss - 2.5694 | 100.601 seconds\n",
      "Epoch  490: gen_loss - 1.8472 | disc_loss - 0.3246 | 100.875 seconds\n",
      "Epoch  500: gen_loss - 1.9015 | disc_loss - 0.3191 | 100.940 seconds\n",
      "Epoch  510: gen_loss - 2.0200 | disc_loss - 0.3064 | 101.080 seconds\n",
      "Epoch  520: gen_loss - 2.0055 | disc_loss - 0.7503 | 100.968 seconds\n",
      "Epoch  530: gen_loss - 1.8964 | disc_loss - 0.4509 | 101.191 seconds\n",
      "Epoch  540: gen_loss - 1.6627 | disc_loss - 0.9233 | 101.040 seconds\n",
      "Epoch  550: gen_loss - 1.1037 | disc_loss - 1.1711 | 101.071 seconds\n",
      "Epoch  560: gen_loss - 0.8425 | disc_loss - 1.1995 | 101.312 seconds\n",
      "Epoch  570: gen_loss - 0.8637 | disc_loss - 1.2046 | 101.333 seconds\n",
      "Epoch  580: gen_loss - 0.9123 | disc_loss - 1.2019 | 100.503 seconds\n",
      "Epoch  590: gen_loss - 0.6790 | disc_loss - 1.3458 | 101.158 seconds\n",
      "Epoch  600: gen_loss - 0.7418 | disc_loss - 1.3380 | 101.316 seconds\n",
      "Epoch  610: gen_loss - 0.7177 | disc_loss - 1.3016 | 101.169 seconds\n",
      "Epoch  620: gen_loss - 0.7360 | disc_loss - 1.2853 | 100.974 seconds\n",
      "Epoch  630: gen_loss - 0.7454 | disc_loss - 1.2802 | 100.826 seconds\n",
      "Epoch  640: gen_loss - 0.7388 | disc_loss - 1.3332 | 101.289 seconds\n",
      "Epoch  650: gen_loss - 0.7375 | disc_loss - 1.3284 | 101.020 seconds\n",
      "Epoch  660: gen_loss - 0.7457 | disc_loss - 1.2762 | 101.413 seconds\n",
      "Epoch  670: gen_loss - 0.7246 | disc_loss - 1.2968 | 101.156 seconds\n",
      "Epoch  680: gen_loss - 0.7467 | disc_loss - 1.3336 | 100.964 seconds\n",
      "Epoch  690: gen_loss - 0.7478 | disc_loss - 1.2737 | 101.240 seconds\n",
      "Epoch  700: gen_loss - 0.7468 | disc_loss - 1.2737 | 100.823 seconds\n",
      "Epoch  710: gen_loss - 0.7719 | disc_loss - 1.2594 | 100.968 seconds\n",
      "Epoch  720: gen_loss - 0.7480 | disc_loss - 1.2588 | 101.004 seconds\n",
      "Epoch  730: gen_loss - 0.7801 | disc_loss - 1.2821 | 101.330 seconds\n",
      "Epoch  740: gen_loss - 0.7879 | disc_loss - 1.2676 | 101.399 seconds\n",
      "Epoch  750: gen_loss - 0.7665 | disc_loss - 1.2742 | 101.198 seconds\n",
      "Epoch  760: gen_loss - 0.7735 | disc_loss - 1.2263 | 100.906 seconds\n",
      "Epoch  770: gen_loss - 0.7566 | disc_loss - 1.3154 | 100.686 seconds\n",
      "Epoch  780: gen_loss - 0.7833 | disc_loss - 1.2844 | 100.726 seconds\n",
      "Epoch  790: gen_loss - 0.7427 | disc_loss - 1.2951 | 100.525 seconds\n",
      "Epoch  800: gen_loss - 0.8115 | disc_loss - 1.2221 | 100.578 seconds\n",
      "Epoch  810: gen_loss - 0.8457 | disc_loss - 1.1785 | 101.015 seconds\n",
      "Epoch  820: gen_loss - 0.7897 | disc_loss - 1.2287 | 101.088 seconds\n",
      "Epoch  830: gen_loss - 0.8917 | disc_loss - 1.0930 | 101.000 seconds\n",
      "Epoch  840: gen_loss - 0.8342 | disc_loss - 1.1063 | 101.153 seconds\n",
      "Epoch  850: gen_loss - 0.8960 | disc_loss - 1.0920 | 100.843 seconds\n",
      "Epoch  860: gen_loss - 0.9360 | disc_loss - 1.0473 | 101.002 seconds\n",
      "Epoch  870: gen_loss - 0.8936 | disc_loss - 1.0140 | 100.799 seconds\n",
      "Epoch  880: gen_loss - 1.1136 | disc_loss - 0.8287 | 101.103 seconds\n",
      "Epoch  890: gen_loss - 2.5513 | disc_loss - 0.1954 | 100.711 seconds\n",
      "Epoch  900: gen_loss - 2.1498 | disc_loss - 0.2140 | 100.726 seconds\n",
      "Epoch  910: gen_loss - 2.3615 | disc_loss - 0.1647 | 100.976 seconds\n",
      "Epoch  920: gen_loss - 2.7238 | disc_loss - 0.1281 | 101.003 seconds\n"
     ]
    }
   ],
   "source": [
    "train(train_dataset, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "generator.save(\"models/generative/generators/generator-v0.3.h5\")\n",
    "discriminator.save(\"models/generative/discriminators/generator-v0.3.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = tf.random.normal([BATCH_SIZE, latent_dim])\n",
    "fake_outputs = discriminator(generator(noise))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(), dtype=float32, numpy=0.054438107>"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_loss(fake_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(14, 1), dtype=float32, numpy=\n",
       "array([[2.8152895],\n",
       "       [3.1792119],\n",
       "       [2.8152776],\n",
       "       [3.1787128],\n",
       "       [2.81529  ],\n",
       "       [2.8152823],\n",
       "       [2.8153174],\n",
       "       [3.1791532],\n",
       "       [2.8153005],\n",
       "       [2.8152924],\n",
       "       [2.8152828],\n",
       "       [2.81532  ],\n",
       "       [2.815322 ],\n",
       "       [2.8153014]], dtype=float32)>"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audiorec",
   "language": "python",
   "name": "audiorec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
