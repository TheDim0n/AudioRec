{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qFi9FiWol1KT"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/physical_device:GPU:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from preprocessing import Audio\n",
    "import tensorflow as tf\n",
    "import tf_train as tft\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import librosa as li\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "%matplotlib inline\n",
    "#tf.debugging.set_log_device_placement(True)\n",
    "GPU = tf.config.list_physical_devices('GPU')\n",
    "CPU = tf.config.list_physical_devices('CPU')\n",
    "DEVICE = GPU[0].name if GPU else CPU[0].name\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Подготовка данных для обучения и тестирования</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    def norm(x):\n",
    "        std = np.std(x, ddof=1)\n",
    "        return (x - np.mean(x)) / std\n",
    "\n",
    "    PATH_0 = r'AudioData/0 Данные' # negative class\n",
    "    PATH_1 = r'AudioData/0 Шум' # noise\n",
    "    PATH_2 = r'AudioData/1 Дио' # positive class\n",
    "\n",
    "    PATHS = li.util.find_files(PATH_0)[:1000] + li.util.find_files(PATH_1) + li.util.find_files(PATH_2)\n",
    "    N = len(PATHS)\n",
    "\n",
    "    np.random.shuffle(PATHS)\n",
    "\n",
    "    DATA = []\n",
    "    LABELS = []\n",
    "    for i, path in enumerate(PATHS):\n",
    "        sound = Audio(path)\n",
    "        e_parts = sound.augmented()\n",
    "        for e in e_parts: \n",
    "            DATA.append(norm(e))\n",
    "            LABELS.append(sound.label)\n",
    "        print('Loading {:.1f}%'.format(i / N * 100))\n",
    "        ipd.clear_output(wait=True)\n",
    "\n",
    "    return (np.array(DATA), np.array(LABELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 99.9%\n"
     ]
    }
   ],
   "source": [
    "data, labels = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((2429, 20), (2429,))"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 1, 20), (None,)), types: (tf.float64, tf.int32)>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = len(data)\n",
    "test_data = np.reshape(data, [BATCH_SIZE, 1, 20])\n",
    "test_labels = np.reshape(labels, [1, BATCH_SIZE])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((test_data, labels))\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Создание модели нейронной сети</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"Jarvis_GRU-v3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, 20)                2460      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 2,502\n",
      "Trainable params: 2,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(1, 20,)),\n",
    "    tf.keras.layers.GRU(20, kernel_regularizer=tf.keras.regularizers.l2(0.01), reset_after=False),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "], name='Jarvis_GRU-v3')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Обучение</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 -- loss_value: 0.717118, Recall: 0.716049, Precision: 0.480000, AUC: 0.552514, time - 0.322s\n",
      "Epoch 100 -- loss_value: 0.440858, Recall: 0.837768, Precision: 0.662034, AUC: 0.750447, time - 3.390s\n",
      "Epoch 200 -- loss_value: 0.357950, Recall: 0.849579, Precision: 0.715751, AUC: 0.791909, time - 3.591s\n",
      "Epoch 300 -- loss_value: 0.310656, Recall: 0.857168, Precision: 0.746872, AUC: 0.814170, time - 4.029s\n",
      "Epoch 400 -- loss_value: 0.277048, Recall: 0.864629, Precision: 0.766421, AUC: 0.828533, time - 3.994s\n",
      "Epoch 500 -- loss_value: 0.250520, Recall: 0.873483, Precision: 0.781556, AUC: 0.840590, time - 3.932s\n",
      "Epoch 600 -- loss_value: 0.227603, Recall: 0.881939, Precision: 0.794275, AUC: 0.851004, time - 3.948s\n",
      "Epoch 700 -- loss_value: 0.206738, Recall: 0.890739, Precision: 0.805365, AUC: 0.860588, time - 3.910s\n",
      "Epoch 800 -- loss_value: 0.187917, Recall: 0.898662, Precision: 0.815384, AUC: 0.869196, time - 3.924s\n",
      "Epoch 900 -- loss_value: 0.171810, Recall: 0.905800, Precision: 0.824357, AUC: 0.876890, time - 3.928s\n",
      "Epoch 1000 -- loss_value: 0.157971, Recall: 0.912135, Precision: 0.832516, AUC: 0.883797, time - 3.906s\n",
      "Epoch 1100 -- loss_value: 0.145677, Recall: 0.917778, Precision: 0.839929, AUC: 0.890003, time - 3.953s\n",
      "Epoch 1200 -- loss_value: 0.134475, Recall: 0.922718, Precision: 0.846752, AUC: 0.895589, time - 3.942s\n",
      "Epoch 1300 -- loss_value: 0.124185, Recall: 0.926915, Precision: 0.852855, AUC: 0.900473, time - 4.018s\n",
      "Epoch 1400 -- loss_value: 0.114883, Recall: 0.930748, Precision: 0.858514, AUC: 0.904963, time - 3.892s\n",
      "Epoch 1500 -- loss_value: 0.106567, Recall: 0.934252, Precision: 0.863638, AUC: 0.909030, time - 3.908s\n",
      "Epoch 1600 -- loss_value: 0.099038, Recall: 0.937512, Precision: 0.868308, AUC: 0.912757, time - 3.944s\n",
      "Epoch 1700 -- loss_value: 0.092109, Recall: 0.940464, Precision: 0.872669, AUC: 0.916188, time - 3.926s\n",
      "Epoch 1800 -- loss_value: 0.085648, Recall: 0.943138, Precision: 0.876732, AUC: 0.919344, time - 3.913s\n",
      "Epoch 1900 -- loss_value: 0.079579, Recall: 0.945748, Precision: 0.880638, AUC: 0.922389, time - 3.915s\n",
      "Epoch 2000 -- loss_value: 0.073851, Recall: 0.948240, Precision: 0.884371, AUC: 0.925292, time - 4.014s\n",
      "Epoch 2100 -- loss_value: 0.068440, Recall: 0.950507, Precision: 0.887991, AUC: 0.928034, time - 3.937s\n",
      "Epoch 2200 -- loss_value: 0.063370, Recall: 0.952569, Precision: 0.891560, AUC: 0.930654, time - 3.906s\n",
      "Epoch 2300 -- loss_value: 0.058665, Recall: 0.954467, Precision: 0.894992, AUC: 0.933129, time - 3.892s\n",
      "Epoch 2400 -- loss_value: 0.054300, Recall: 0.956220, Precision: 0.898290, AUC: 0.935469, time - 3.946s\n",
      "Epoch 2500 -- loss_value: 0.050212, Recall: 0.957844, Precision: 0.901417, AUC: 0.937665, time - 3.889s\n",
      "Epoch 2600 -- loss_value: 0.046346, Recall: 0.959359, Precision: 0.904357, AUC: 0.939720, time - 3.941s\n",
      "Epoch 2700 -- loss_value: 0.042746, Recall: 0.960773, Precision: 0.907120, AUC: 0.941643, time - 3.890s\n",
      "Epoch 2800 -- loss_value: 0.039432, Recall: 0.962110, Precision: 0.909738, AUC: 0.943460, time - 3.969s\n",
      "Epoch 2900 -- loss_value: 0.036390, Recall: 0.963369, Precision: 0.912267, AUC: 0.945196, time - 3.925s\n",
      "Epoch 3000 -- loss_value: 0.033600, Recall: 0.964544, Precision: 0.914668, AUC: 0.946832, time - 3.976s\n",
      "Epoch 3100 -- loss_value: 0.031035, Recall: 0.965643, Precision: 0.916982, AUC: 0.948390, time - 4.263s\n",
      "Epoch 3200 -- loss_value: 0.028661, Recall: 0.966674, Precision: 0.919211, AUC: 0.949876, time - 3.895s\n",
      "Epoch 3300 -- loss_value: 0.026440, Recall: 0.967646, Precision: 0.921393, AUC: 0.951311, time - 3.898s\n",
      "Epoch 3400 -- loss_value: 0.024356, Recall: 0.968578, Precision: 0.923454, AUC: 0.952669, time - 3.917s\n",
      "Epoch 3500 -- loss_value: 0.022414, Recall: 0.969456, Precision: 0.925401, AUC: 0.953949, time - 3.925s\n",
      "Epoch 3600 -- loss_value: 0.020609, Recall: 0.970285, Precision: 0.927249, AUC: 0.955160, time - 3.938s\n",
      "Epoch 3700 -- loss_value: 0.018936, Recall: 0.971069, Precision: 0.929021, AUC: 0.956315, time - 3.903s\n",
      "Epoch 3800 -- loss_value: 0.017390, Recall: 0.971812, Precision: 0.930722, AUC: 0.957417, time - 3.879s\n",
      "Epoch 3900 -- loss_value: 0.015965, Recall: 0.972517, Precision: 0.932345, AUC: 0.958465, time - 3.932s\n",
      "Epoch 4000 -- loss_value: 0.014654, Recall: 0.973187, Precision: 0.933914, AUC: 0.959472, time - 3.884s\n",
      "Epoch 4100 -- loss_value: 0.013452, Recall: 0.973824, Precision: 0.935416, AUC: 0.960432, time - 3.930s\n",
      "Epoch 4200 -- loss_value: 0.012353, Recall: 0.974431, Precision: 0.936860, AUC: 0.961351, time - 3.925s\n",
      "Epoch 4300 -- loss_value: 0.011352, Recall: 0.975009, Precision: 0.938243, AUC: 0.962229, time - 3.949s\n",
      "Epoch 4400 -- loss_value: 0.010441, Recall: 0.975562, Precision: 0.939565, AUC: 0.963067, time - 4.054s\n",
      "Epoch 4500 -- loss_value: 0.009614, Recall: 0.976090, Precision: 0.940845, AUC: 0.963875, time - 4.155s\n",
      "Epoch 4600 -- loss_value: 0.008861, Recall: 0.976610, Precision: 0.942072, AUC: 0.964654, time - 3.944s\n",
      "Epoch 4700 -- loss_value: 0.008177, Recall: 0.977108, Precision: 0.943248, AUC: 0.965400, time - 3.912s\n",
      "Epoch 4800 -- loss_value: 0.007553, Recall: 0.977584, Precision: 0.944377, AUC: 0.966115, time - 3.909s\n",
      "Epoch 4900 -- loss_value: 0.006984, Recall: 0.978042, Precision: 0.945462, AUC: 0.966801, time - 3.932s\n",
      "Epoch 5000 -- loss_value: 0.006465, Recall: 0.978481, Precision: 0.946517, AUC: 0.967465, time - 4.020s\n",
      "Model training takes 196.738 seconds.\n"
     ]
    }
   ],
   "source": [
    "tft.train(\n",
    "    train_dataset=dataset,\n",
    "    model=model,\n",
    "    epochs=5000,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\n",
    "        tft.metrics.Recall(),\n",
    "        tft.metrics.Precision(),\n",
    "        tft.metrics.AUC(),\n",
    "    ],\n",
    "    frequency=100\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(r'models\\v3\\{}.h5'.format(model.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"Jarvis_GRU-v3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru (GRU)                    (None, 20)                2460      \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 2)                 42        \n",
      "=================================================================\n",
      "Total params: 2,502\n",
      "Trainable params: 2,502\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(r'models/v3/Jarvis_GRU-v3.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loss_value: 1.870327, Recall: 0.462441, Precision: 1.000000, AUC: 0.731221, \n"
     ]
    }
   ],
   "source": [
    "tft.evaluate(\n",
    "    dataset,\n",
    "    model,\n",
    "    loss=tft.losses.SparseCategoricalCrossentropy(),\n",
    "    metrics=[\n",
    "        tft.metrics.Recall(),\n",
    "        tft.metrics.Precision(),\n",
    "        tft.metrics.AUC(),\n",
    "    ],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'predictions' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-22-f73e366f1a02>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mn\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mpredictions\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlabels\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;36m100\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'predictions' is not defined"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    n += int(labels[i] == predictions[i])\n",
    "\n",
    "print(n, n / len(labels) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 0, 1, 1, 0, 0, 0, 0, 3, 0], dtype=int64)>,\n",
       " array([0, 0, 1, 1, 0, 0, 0, 0, 3, 0]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[60:70], labels[60:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(15,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], dtype=int64)>,\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:15], labels[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[60:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'test.tfrecord'\n",
    "writer_data = tf.data.experimental.TFRecordWriter(\"datasets\\Mira\\data.tfrecord\")\n",
    "writer_labels = tf.data.experimental.TFRecordWriter(\"datasets\\Mira\\labels.tfrecord\")\n",
    "test_data = tf.data.Dataset.from_tensor_slices(data)\n",
    "test_labels = tf.data.Dataset.from_tensor_slices(labels)\n",
    "test_data = test_data.map(lambda x: str(x))\n",
    "test_labels = test_labels.map(lambda x: str(x))\n",
    "writer_data.write(test_data)\n",
    "writer_labels.write(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dataset = tf.data.TFRecordDataset([\"datasets\\Mira\\labels.tfrecord\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'Tensor(\"args_0:0\", shape=(), dtype=int32)', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for d in loaded_dataset.take(1):\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Tensor(\"args_0:0\", shape=(20,), dtype=float64)'\n"
     ]
    }
   ],
   "source": [
    "for d in test_data.take(1):\n",
    "    print(d.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "predictions must be <= 1\nCondition x <= y did not hold.\nFirst 3 elements of x:\n[1. 0. 1.]\nFirst 1 elements of y:\n[1.]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-f23c066cb68c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRecall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[1;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_context_for_symbolic_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m       \u001b[0mupdate_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_state_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# update_op will be None in eager execution.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m       \u001b[0mmetric_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mupdate_state\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m   1380\u001b[0m       \u001b[0mUpdate\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m     \"\"\"\n\u001b[1;32m-> 1382\u001b[1;33m     return metrics_utils.update_confusion_matrix_variables(\n\u001b[0m\u001b[0;32m   1383\u001b[0m         {\n\u001b[0;32m   1384\u001b[0m             \u001b[0mmetrics_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfusionMatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRUE_POSITIVES\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrue_positives\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\metrics_utils.py\u001b[0m in \u001b[0;36mupdate_confusion_matrix_variables\u001b[1;34m(variables_to_update, y_true, y_pred, thresholds, top_k, class_id, sample_weight, multi_label, label_weights)\u001b[0m\n\u001b[0;32m    337\u001b[0m           \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m           message='predictions must be >= 0'),\n\u001b[1;32m--> 339\u001b[1;33m       check_ops.assert_less_equal(\n\u001b[0m\u001b[0;32m    340\u001b[0m           \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m           \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\check_ops.py\u001b[0m in \u001b[0;36massert_less_equal\u001b[1;34m(x, y, data, summarize, message, name)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_binary_assert_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<='\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0massert_less_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 923\u001b[1;33m   return _binary_assert('<=', 'assert_less_equal', math_ops.less_equal,\n\u001b[0m\u001b[0;32m    924\u001b[0m                         np.less_equal, x, y, data, summarize, message, name)\n\u001b[0;32m    925\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\check_ops.py\u001b[0m in \u001b[0;36m_binary_assert\u001b[1;34m(sym, opname, op_func, static_func, x, y, data, summarize, message, name)\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m       raise errors.InvalidArgumentError(\n\u001b[0m\u001b[0;32m    353\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m           \u001b[0mop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: predictions must be <= 1\nCondition x <= y did not hold.\nFirst 3 elements of x:\n[1. 0. 1.]\nFirst 1 elements of y:\n[1.]"
     ]
    }
   ],
   "source": [
    "m = tf.keras.metrics.Recall(class_id=1)\n",
    "m.update_state([1, 0, 1, 2], [1, 0, 1, 2])\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
       "array([0.98039216, 0.00272254, 0.00372326, 0.00742231, 0.00221274,\n",
       "       0.00352691], dtype=float32)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = tf.nn.softmax(model(test_data[:1]))[0]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "predictions must be <= 1\nCondition x <= y did not hold.\nFirst 3 elements of x:\n[1. 2. 3.]\nFirst 1 elements of y:\n[1.]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-a1e5f06a2b2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTruePositives\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[1;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_context_for_symbolic_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m       \u001b[0mupdate_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_state_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# update_op will be None in eager execution.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m       \u001b[0mmetric_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mupdate_state\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m    934\u001b[0m       \u001b[0mUpdate\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m     \"\"\"\n\u001b[1;32m--> 936\u001b[1;33m     return metrics_utils.update_confusion_matrix_variables(\n\u001b[0m\u001b[0;32m    937\u001b[0m         \u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_confusion_matrix_cond\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccumulator\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\metrics_utils.py\u001b[0m in \u001b[0;36mupdate_confusion_matrix_variables\u001b[1;34m(variables_to_update, y_true, y_pred, thresholds, top_k, class_id, sample_weight, multi_label, label_weights)\u001b[0m\n\u001b[0;32m    337\u001b[0m           \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m           message='predictions must be >= 0'),\n\u001b[1;32m--> 339\u001b[1;33m       check_ops.assert_less_equal(\n\u001b[0m\u001b[0;32m    340\u001b[0m           \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m           \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\check_ops.py\u001b[0m in \u001b[0;36massert_less_equal\u001b[1;34m(x, y, data, summarize, message, name)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_binary_assert_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<='\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0massert_less_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 923\u001b[1;33m   return _binary_assert('<=', 'assert_less_equal', math_ops.less_equal,\n\u001b[0m\u001b[0;32m    924\u001b[0m                         np.less_equal, x, y, data, summarize, message, name)\n\u001b[0;32m    925\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\check_ops.py\u001b[0m in \u001b[0;36m_binary_assert\u001b[1;34m(sym, opname, op_func, static_func, x, y, data, summarize, message, name)\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m       raise errors.InvalidArgumentError(\n\u001b[0m\u001b[0;32m    353\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m           \u001b[0mop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: predictions must be <= 1\nCondition x <= y did not hold.\nFirst 3 elements of x:\n[1. 2. 3.]\nFirst 1 elements of y:\n[1.]"
     ]
    }
   ],
   "source": [
    "m = tf.keras.metrics.TruePositives()\n",
    "m.update_state([1, 2, 3], [1, 2, 3])\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 3,\n",
       "        0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>,\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 3,\n",
       "        0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:100], labels[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rtuassistant-starter",
   "language": "python",
   "name": "rtuassistant-starter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
