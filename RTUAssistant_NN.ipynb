{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qFi9FiWol1KT"
   },
   "outputs": [],
   "source": [
    "from preprocessing import Audio\n",
    "import tensorflow as tf\n",
    "import tf_train as tft\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import librosa as li\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "%matplotlib inline\n",
    "#tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/physical_device:GPU:0'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GPU = tf.config.list_physical_devices('GPU')\n",
    "CPU = tf.config.list_physical_devices('CPU')\n",
    "DEVICE = GPU[0].name if GPU else CPU[0].name\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Подготовка данных для обучения и тестирования</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    def norm(x):\n",
    "        std = np.std(x, ddof=1)\n",
    "        return (x - np.mean(x)) / std\n",
    "\n",
    "    PATH_0 = r'AudioData/0 Данные' # negative class\n",
    "    PATH_1 = r'AudioData/1 Джарвис' # positive class\n",
    "\n",
    "    PATHS = li.util.find_files(PATH_0)[:3000] + li.util.find_files(PATH_1)\n",
    "    N = len(PATHS)\n",
    "\n",
    "    np.random.shuffle(PATHS)\n",
    "\n",
    "    SOUNDS = []\n",
    "    for path in PATHS:\n",
    "        SOUNDS.append(Audio(path))\n",
    "        print('Loading {:.1f}%'.format(len(SOUNDS) / N * 100))\n",
    "        ipd.clear_output(wait=True)\n",
    "    DATA = []\n",
    "    LABELS = []\n",
    "\n",
    "    for sound in SOUNDS:\n",
    "        DATA.append(norm(sound.e_parts))\n",
    "        LABELS.append(sound.label)\n",
    "\n",
    "    return (np.array(DATA), np.array(LABELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading 100.0%\n"
     ]
    }
   ],
   "source": [
    "data, labels = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_labels = data[8000:], labels[8000:]\n",
    "data, labels = data[:8000], labels[:8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((3361, 20), (3361,))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 20), (None,)), types: (tf.float64, tf.int32)>"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 1081\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<BatchDataset shapes: ((None, 1, 20), (None,)), types: (tf.float64, tf.int32)>"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "BATCH_SIZE = 3361\n",
    "test_data = np.reshape(data, [3361, 1, 20])\n",
    "test_labels = np.reshape(labels, [1, 3361])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((test_data, labels))\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.reshape(data, (10070, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.reshape(labels, (10070,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, ..., 0, 0, 0]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_labels[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Создание модели нейронной сети</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\n",
      "Model: \"All_GRU\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "gru_4 (GRU)                  (None, 20)                2460      \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 6)                 126       \n",
      "=================================================================\n",
      "Total params: 2,586\n",
      "Trainable params: 2,586\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(1, 20,)),\n",
    "    tf.keras.layers.GRU(20, kernel_regularizer=tf.keras.regularizers.l2(0.01), reset_after=False),\n",
    "    # tf.keras.layers.Dense(100, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    # tf.keras.layers.Dense(50, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    # tf.keras.layers.Dense(25, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    # tf.keras.layers.Dense(12, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dense(6)\n",
    "], name='All_GRU')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Обучение</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 000 -- Loss(SparseCategoricalCrossentropy): 0.583, Accuracy: 0.8893186450004578\n",
      "Epoch 010 -- Loss(SparseCategoricalCrossentropy): 0.578, Accuracy: 0.8893186450004578\n",
      "Epoch 020 -- Loss(SparseCategoricalCrossentropy): 0.573, Accuracy: 0.8893186450004578\n",
      "Epoch 030 -- Loss(SparseCategoricalCrossentropy): 0.568, Accuracy: 0.8893186450004578\n",
      "Epoch 040 -- Loss(SparseCategoricalCrossentropy): 0.564, Accuracy: 0.8893404006958008\n",
      "Epoch 050 -- Loss(SparseCategoricalCrossentropy): 0.559, Accuracy: 0.8893945217132568\n",
      "Epoch 060 -- Loss(SparseCategoricalCrossentropy): 0.555, Accuracy: 0.889430820941925\n",
      "Epoch 070 -- Loss(SparseCategoricalCrossentropy): 0.551, Accuracy: 0.8894569277763367\n",
      "Epoch 080 -- Loss(SparseCategoricalCrossentropy): 0.547, Accuracy: 0.8894765973091125\n",
      "Epoch 090 -- Loss(SparseCategoricalCrossentropy): 0.543, Accuracy: 0.8894919157028198\n",
      "Epoch 100 -- Loss(SparseCategoricalCrossentropy): 0.539, Accuracy: 0.8895101547241211\n",
      "Epoch 110 -- Loss(SparseCategoricalCrossentropy): 0.536, Accuracy: 0.8895465135574341\n",
      "Epoch 120 -- Loss(SparseCategoricalCrossentropy): 0.532, Accuracy: 0.8895989656448364\n",
      "Epoch 130 -- Loss(SparseCategoricalCrossentropy): 0.529, Accuracy: 0.8896456956863403\n",
      "Epoch 140 -- Loss(SparseCategoricalCrossentropy): 0.526, Accuracy: 0.8896858096122742\n",
      "Epoch 150 -- Loss(SparseCategoricalCrossentropy): 0.523, Accuracy: 0.889720618724823\n",
      "Epoch 160 -- Loss(SparseCategoricalCrossentropy): 0.520, Accuracy: 0.8897510766983032\n",
      "Epoch 170 -- Loss(SparseCategoricalCrossentropy): 0.517, Accuracy: 0.8897780179977417\n",
      "Epoch 180 -- Loss(SparseCategoricalCrossentropy): 0.514, Accuracy: 0.8898183703422546\n",
      "Epoch 190 -- Loss(SparseCategoricalCrossentropy): 0.512, Accuracy: 0.8898545503616333\n",
      "Epoch 200 -- Loss(SparseCategoricalCrossentropy): 0.509, Accuracy: 0.8898870944976807\n",
      "Epoch 210 -- Loss(SparseCategoricalCrossentropy): 0.507, Accuracy: 0.8899165391921997\n",
      "Epoch 220 -- Loss(SparseCategoricalCrossentropy): 0.504, Accuracy: 0.8899433612823486\n",
      "Epoch 230 -- Loss(SparseCategoricalCrossentropy): 0.502, Accuracy: 0.8899677991867065\n",
      "Epoch 240 -- Loss(SparseCategoricalCrossentropy): 0.500, Accuracy: 0.8899902701377869\n",
      "Epoch 250 -- Loss(SparseCategoricalCrossentropy): 0.498, Accuracy: 0.8900108933448792\n",
      "Epoch 260 -- Loss(SparseCategoricalCrossentropy): 0.495, Accuracy: 0.8900414109230042\n",
      "Epoch 270 -- Loss(SparseCategoricalCrossentropy): 0.493, Accuracy: 0.8900696039199829\n",
      "Epoch 280 -- Loss(SparseCategoricalCrossentropy): 0.491, Accuracy: 0.8900958299636841\n",
      "Epoch 290 -- Loss(SparseCategoricalCrossentropy): 0.489, Accuracy: 0.890120267868042\n",
      "Epoch 300 -- Loss(SparseCategoricalCrossentropy): 0.488, Accuracy: 0.8901430368423462\n",
      "Epoch 310 -- Loss(SparseCategoricalCrossentropy): 0.486, Accuracy: 0.8901643753051758\n",
      "Epoch 320 -- Loss(SparseCategoricalCrossentropy): 0.484, Accuracy: 0.8901843428611755\n",
      "Epoch 330 -- Loss(SparseCategoricalCrossentropy): 0.482, Accuracy: 0.8902031779289246\n",
      "Epoch 340 -- Loss(SparseCategoricalCrossentropy): 0.480, Accuracy: 0.8902208209037781\n",
      "Epoch 350 -- Loss(SparseCategoricalCrossentropy): 0.479, Accuracy: 0.8902375102043152\n",
      "Epoch 360 -- Loss(SparseCategoricalCrossentropy): 0.477, Accuracy: 0.8902533054351807\n",
      "Epoch 370 -- Loss(SparseCategoricalCrossentropy): 0.476, Accuracy: 0.8902682065963745\n",
      "Epoch 380 -- Loss(SparseCategoricalCrossentropy): 0.474, Accuracy: 0.8902823328971863\n",
      "Epoch 390 -- Loss(SparseCategoricalCrossentropy): 0.473, Accuracy: 0.890295684337616\n",
      "Epoch 400 -- Loss(SparseCategoricalCrossentropy): 0.471, Accuracy: 0.8903114199638367\n",
      "Epoch 410 -- Loss(SparseCategoricalCrossentropy): 0.470, Accuracy: 0.8903306722640991\n",
      "Epoch 420 -- Loss(SparseCategoricalCrossentropy): 0.468, Accuracy: 0.8903490304946899\n",
      "Epoch 430 -- Loss(SparseCategoricalCrossentropy): 0.467, Accuracy: 0.8903665542602539\n",
      "Epoch 440 -- Loss(SparseCategoricalCrossentropy): 0.466, Accuracy: 0.8903833031654358\n",
      "Epoch 450 -- Loss(SparseCategoricalCrossentropy): 0.464, Accuracy: 0.8904018998146057\n",
      "Epoch 460 -- Loss(SparseCategoricalCrossentropy): 0.463, Accuracy: 0.890423595905304\n",
      "Epoch 470 -- Loss(SparseCategoricalCrossentropy): 0.462, Accuracy: 0.8904468417167664\n",
      "Epoch 480 -- Loss(SparseCategoricalCrossentropy): 0.461, Accuracy: 0.8904728889465332\n",
      "Epoch 490 -- Loss(SparseCategoricalCrossentropy): 0.459, Accuracy: 0.8904978632926941\n",
      "Epoch 500 -- Loss(SparseCategoricalCrossentropy): 0.458, Accuracy: 0.8905218243598938\n",
      "Epoch 510 -- Loss(SparseCategoricalCrossentropy): 0.457, Accuracy: 0.8905489444732666\n",
      "Epoch 520 -- Loss(SparseCategoricalCrossentropy): 0.456, Accuracy: 0.8905767202377319\n",
      "Epoch 530 -- Loss(SparseCategoricalCrossentropy): 0.455, Accuracy: 0.8906034827232361\n",
      "Epoch 540 -- Loss(SparseCategoricalCrossentropy): 0.454, Accuracy: 0.890629231929779\n",
      "Epoch 550 -- Loss(SparseCategoricalCrossentropy): 0.453, Accuracy: 0.8906540274620056\n",
      "Epoch 560 -- Loss(SparseCategoricalCrossentropy): 0.452, Accuracy: 0.8906779885292053\n",
      "Epoch 570 -- Loss(SparseCategoricalCrossentropy): 0.451, Accuracy: 0.8907010555267334\n",
      "Epoch 580 -- Loss(SparseCategoricalCrossentropy): 0.450, Accuracy: 0.8907233476638794\n",
      "Epoch 590 -- Loss(SparseCategoricalCrossentropy): 0.449, Accuracy: 0.8907448649406433\n",
      "Epoch 600 -- Loss(SparseCategoricalCrossentropy): 0.448, Accuracy: 0.8907657265663147\n",
      "Epoch 610 -- Loss(SparseCategoricalCrossentropy): 0.447, Accuracy: 0.8907858729362488\n",
      "Epoch 620 -- Loss(SparseCategoricalCrossentropy): 0.446, Accuracy: 0.8908053636550903\n",
      "Epoch 630 -- Loss(SparseCategoricalCrossentropy): 0.445, Accuracy: 0.8908241987228394\n",
      "Epoch 640 -- Loss(SparseCategoricalCrossentropy): 0.444, Accuracy: 0.8908424973487854\n",
      "Epoch 650 -- Loss(SparseCategoricalCrossentropy): 0.443, Accuracy: 0.8908602595329285\n",
      "Epoch 660 -- Loss(SparseCategoricalCrossentropy): 0.442, Accuracy: 0.8908774256706238\n",
      "Epoch 670 -- Loss(SparseCategoricalCrossentropy): 0.441, Accuracy: 0.8908941149711609\n",
      "Epoch 680 -- Loss(SparseCategoricalCrossentropy): 0.440, Accuracy: 0.890910267829895\n",
      "Epoch 690 -- Loss(SparseCategoricalCrossentropy): 0.439, Accuracy: 0.8909260034561157\n",
      "Epoch 700 -- Loss(SparseCategoricalCrossentropy): 0.439, Accuracy: 0.8909412622451782\n",
      "Epoch 710 -- Loss(SparseCategoricalCrossentropy): 0.438, Accuracy: 0.8909561038017273\n",
      "Epoch 720 -- Loss(SparseCategoricalCrossentropy): 0.437, Accuracy: 0.8909705281257629\n",
      "Epoch 730 -- Loss(SparseCategoricalCrossentropy): 0.436, Accuracy: 0.8909845948219299\n",
      "Epoch 740 -- Loss(SparseCategoricalCrossentropy): 0.435, Accuracy: 0.8909982442855835\n",
      "Epoch 750 -- Loss(SparseCategoricalCrossentropy): 0.434, Accuracy: 0.8910115361213684\n",
      "Epoch 760 -- Loss(SparseCategoricalCrossentropy): 0.434, Accuracy: 0.8910244703292847\n",
      "Epoch 770 -- Loss(SparseCategoricalCrossentropy): 0.433, Accuracy: 0.891037106513977\n",
      "Epoch 780 -- Loss(SparseCategoricalCrossentropy): 0.432, Accuracy: 0.8910493850708008\n",
      "Epoch 790 -- Loss(SparseCategoricalCrossentropy): 0.431, Accuracy: 0.8910613059997559\n",
      "Epoch 800 -- Loss(SparseCategoricalCrossentropy): 0.430, Accuracy: 0.8910729885101318\n",
      "Epoch 810 -- Loss(SparseCategoricalCrossentropy): 0.430, Accuracy: 0.8910843729972839\n",
      "Epoch 820 -- Loss(SparseCategoricalCrossentropy): 0.429, Accuracy: 0.8910955190658569\n",
      "Epoch 830 -- Loss(SparseCategoricalCrossentropy): 0.428, Accuracy: 0.891106367111206\n",
      "Epoch 840 -- Loss(SparseCategoricalCrossentropy): 0.427, Accuracy: 0.8911169171333313\n",
      "Epoch 850 -- Loss(SparseCategoricalCrossentropy): 0.427, Accuracy: 0.8911272883415222\n",
      "Epoch 860 -- Loss(SparseCategoricalCrossentropy): 0.426, Accuracy: 0.8911373615264893\n",
      "Epoch 870 -- Loss(SparseCategoricalCrossentropy): 0.425, Accuracy: 0.8911471962928772\n",
      "Epoch 880 -- Loss(SparseCategoricalCrossentropy): 0.424, Accuracy: 0.8911568522453308\n",
      "Epoch 890 -- Loss(SparseCategoricalCrossentropy): 0.424, Accuracy: 0.8911662697792053\n",
      "Epoch 900 -- Loss(SparseCategoricalCrossentropy): 0.423, Accuracy: 0.8911755084991455\n",
      "Epoch 910 -- Loss(SparseCategoricalCrossentropy): 0.422, Accuracy: 0.8911845088005066\n",
      "Epoch 920 -- Loss(SparseCategoricalCrossentropy): 0.421, Accuracy: 0.8911991119384766\n",
      "Epoch 930 -- Loss(SparseCategoricalCrossentropy): 0.421, Accuracy: 0.8912140727043152\n",
      "Epoch 940 -- Loss(SparseCategoricalCrossentropy): 0.420, Accuracy: 0.8912287354469299\n",
      "Epoch 950 -- Loss(SparseCategoricalCrossentropy): 0.419, Accuracy: 0.891243040561676\n",
      "Epoch 960 -- Loss(SparseCategoricalCrossentropy): 0.418, Accuracy: 0.891257107257843\n",
      "Epoch 970 -- Loss(SparseCategoricalCrossentropy): 0.418, Accuracy: 0.8912708163261414\n",
      "Epoch 980 -- Loss(SparseCategoricalCrossentropy): 0.417, Accuracy: 0.8912842869758606\n",
      "Epoch 990 -- Loss(SparseCategoricalCrossentropy): 0.416, Accuracy: 0.891297459602356\n",
      "Epoch 1000 -- Loss(SparseCategoricalCrossentropy): 0.416, Accuracy: 0.8913103938102722\n"
     ]
    }
   ],
   "source": [
    "tft.train(\n",
    "    train_dataset=dataset,\n",
    "    model=model,\n",
    "    epochs=1000,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models\\{}-v1.0.h5'.format(model.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                252       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 26        \n",
      "=================================================================\n",
      "Total params: 278\n",
      "Trainable params: 278\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(r'models\\Mira-v1.0.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device(\"CPU\"):\n",
    "    predictions = tft.predict_classes(model=model, features=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3361 100.0\n"
     ]
    }
   ],
   "source": [
    "n = 0\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    n += int(labels[i] == predictions[i])\n",
    "\n",
    "print(n, n / len(labels) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 0, 1, 1, 0, 0, 0, 0, 3, 0], dtype=int64)>,\n",
       " array([0, 0, 1, 1, 0, 0, 0, 0, 3, 0]))"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[60:70], labels[60:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(15,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], dtype=int64)>,\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:15], labels[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[60:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'test.tfrecord'\n",
    "writer_data = tf.data.experimental.TFRecordWriter(\"datasets\\Mira\\data.tfrecord\")\n",
    "writer_labels = tf.data.experimental.TFRecordWriter(\"datasets\\Mira\\labels.tfrecord\")\n",
    "test_data = tf.data.Dataset.from_tensor_slices(data)\n",
    "test_labels = tf.data.Dataset.from_tensor_slices(labels)\n",
    "test_data = test_data.map(lambda x: str(x))\n",
    "test_labels = test_labels.map(lambda x: str(x))\n",
    "writer_data.write(test_data)\n",
    "writer_labels.write(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dataset = tf.data.TFRecordDataset([\"datasets\\Mira\\labels.tfrecord\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor(b'Tensor(\"args_0:0\", shape=(), dtype=int32)', shape=(), dtype=string)\n"
     ]
    }
   ],
   "source": [
    "for d in loaded_dataset.take(1):\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<TFRecordDatasetV2 shapes: (), types: tf.string>"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loaded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Tensor(\"args_0:0\", shape=(20,), dtype=float64)'\n"
     ]
    }
   ],
   "source": [
    "for d in test_data.take(1):\n",
    "    print(d.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "predictions must be <= 1\nCondition x <= y did not hold.\nFirst 3 elements of x:\n[1. 0. 1.]\nFirst 1 elements of y:\n[1.]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-f23c066cb68c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRecall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[1;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_context_for_symbolic_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m       \u001b[0mupdate_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_state_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# update_op will be None in eager execution.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m       \u001b[0mmetric_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mupdate_state\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m   1380\u001b[0m       \u001b[0mUpdate\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m     \"\"\"\n\u001b[1;32m-> 1382\u001b[1;33m     return metrics_utils.update_confusion_matrix_variables(\n\u001b[0m\u001b[0;32m   1383\u001b[0m         {\n\u001b[0;32m   1384\u001b[0m             \u001b[0mmetrics_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfusionMatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRUE_POSITIVES\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrue_positives\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\metrics_utils.py\u001b[0m in \u001b[0;36mupdate_confusion_matrix_variables\u001b[1;34m(variables_to_update, y_true, y_pred, thresholds, top_k, class_id, sample_weight, multi_label, label_weights)\u001b[0m\n\u001b[0;32m    337\u001b[0m           \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m           message='predictions must be >= 0'),\n\u001b[1;32m--> 339\u001b[1;33m       check_ops.assert_less_equal(\n\u001b[0m\u001b[0;32m    340\u001b[0m           \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m           \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\check_ops.py\u001b[0m in \u001b[0;36massert_less_equal\u001b[1;34m(x, y, data, summarize, message, name)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_binary_assert_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<='\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0massert_less_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 923\u001b[1;33m   return _binary_assert('<=', 'assert_less_equal', math_ops.less_equal,\n\u001b[0m\u001b[0;32m    924\u001b[0m                         np.less_equal, x, y, data, summarize, message, name)\n\u001b[0;32m    925\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\check_ops.py\u001b[0m in \u001b[0;36m_binary_assert\u001b[1;34m(sym, opname, op_func, static_func, x, y, data, summarize, message, name)\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m       raise errors.InvalidArgumentError(\n\u001b[0m\u001b[0;32m    353\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m           \u001b[0mop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: predictions must be <= 1\nCondition x <= y did not hold.\nFirst 3 elements of x:\n[1. 0. 1.]\nFirst 1 elements of y:\n[1.]"
     ]
    }
   ],
   "source": [
    "m = tf.keras.metrics.Recall(class_id=1)\n",
    "m.update_state([1, 0, 1, 2], [1, 0, 1, 2])\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tf.Tensor: shape=(6,), dtype=float32, numpy=\n",
       "array([0.98039216, 0.00272254, 0.00372326, 0.00742231, 0.00221274,\n",
       "       0.00352691], dtype=float32)>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = tf.nn.softmax(model(test_data[:1]))[0]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "ename": "InvalidArgumentError",
     "evalue": "predictions must be <= 1\nCondition x <= y did not hold.\nFirst 3 elements of x:\n[1. 2. 3.]\nFirst 1 elements of y:\n[1.]",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-a1e5f06a2b2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTruePositives\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[1;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_context_for_symbolic_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m       \u001b[0mupdate_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_state_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# update_op will be None in eager execution.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m       \u001b[0mmetric_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mupdate_state\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m    934\u001b[0m       \u001b[0mUpdate\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m     \"\"\"\n\u001b[1;32m--> 936\u001b[1;33m     return metrics_utils.update_confusion_matrix_variables(\n\u001b[0m\u001b[0;32m    937\u001b[0m         \u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_confusion_matrix_cond\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccumulator\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\metrics_utils.py\u001b[0m in \u001b[0;36mupdate_confusion_matrix_variables\u001b[1;34m(variables_to_update, y_true, y_pred, thresholds, top_k, class_id, sample_weight, multi_label, label_weights)\u001b[0m\n\u001b[0;32m    337\u001b[0m           \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m           message='predictions must be >= 0'),\n\u001b[1;32m--> 339\u001b[1;33m       check_ops.assert_less_equal(\n\u001b[0m\u001b[0;32m    340\u001b[0m           \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m           \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\check_ops.py\u001b[0m in \u001b[0;36massert_less_equal\u001b[1;34m(x, y, data, summarize, message, name)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_binary_assert_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<='\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0massert_less_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 923\u001b[1;33m   return _binary_assert('<=', 'assert_less_equal', math_ops.less_equal,\n\u001b[0m\u001b[0;32m    924\u001b[0m                         np.less_equal, x, y, data, summarize, message, name)\n\u001b[0;32m    925\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\check_ops.py\u001b[0m in \u001b[0;36m_binary_assert\u001b[1;34m(sym, opname, op_func, static_func, x, y, data, summarize, message, name)\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m       raise errors.InvalidArgumentError(\n\u001b[0m\u001b[0;32m    353\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m           \u001b[0mop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: predictions must be <= 1\nCondition x <= y did not hold.\nFirst 3 elements of x:\n[1. 2. 3.]\nFirst 1 elements of y:\n[1.]"
     ]
    }
   ],
   "source": [
    "m = tf.keras.metrics.TruePositives()\n",
    "m.update_state([1, 2, 3], [1, 2, 3])\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(100,), dtype=int64, numpy=\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 3,\n",
       "        0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>,\n",
       " array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 3,\n",
       "        0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n",
       "        0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions[:100], labels[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "rtuassistant-starter",
   "language": "python",
   "name": "rtuassistant-starter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
