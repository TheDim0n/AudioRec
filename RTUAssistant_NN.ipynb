{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qFi9FiWol1KT"
   },
   "outputs": [],
   "source": [
    "from preprocessing import Audio\n",
    "import tensorflow as tf\n",
    "import tf_train as tft\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import librosa as li\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "%matplotlib inline\n",
    "#tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'/device:GPU:0'"
     },
     "metadata": {},
     "execution_count": 3
    }
   ],
   "source": [
    "GPU = tf.config.list_logical_devices('GPU')\n",
    "CPU = tf.config.list_logical_devices('CPU')\n",
    "DEVICE = GPU[0].name if GPU else CPU[0].name\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Подготовка данных для обучения и тестирования</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    def norm(x):\n",
    "        std = np.std(x ,ddof=1)\n",
    "        return (x - np.mean(x)) / std\n",
    "\n",
    "    PATH_0 = r'AudioData/0 Данные' # negative class\n",
    "    PATH_1 = r'AudioData/1 Мира' # positive class\n",
    "\n",
    "    PATHS = li.util.find_files(PATH_0)[:1000] + li.util.find_files(PATH_1)\n",
    "    N = len(PATHS)\n",
    "\n",
    "    np.random.shuffle(PATHS)\n",
    "\n",
    "    SOUNDS = []\n",
    "    for path in PATHS:\n",
    "        SOUNDS.append(Audio(path))\n",
    "        print('Loading {:.1f}%'.format(len(SOUNDS) / N * 100))\n",
    "        ipd.clear_output(wait=True)\n",
    "    DATA = []\n",
    "    LABELS = []\n",
    "\n",
    "    for sound in SOUNDS:\n",
    "        DATA.append(norm(sound.e_parts))\n",
    "        LABELS.append(sound.label)\n",
    "\n",
    "    return (np.array(DATA), np.array(LABELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loading 100.0%\n"
    }
   ],
   "source": [
    "data, labels = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((1070, 20), (1070,))"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "data.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<BatchDataset shapes: ((None, 20), (None,)), types: (tf.float64, tf.int32)>"
     },
     "metadata": {},
     "execution_count": 7
    }
   ],
   "source": [
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(107)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.reshape(data, (10070, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.reshape(labels, (10070,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0],\n",
       "       [0],\n",
       "       [0],\n",
       "       ...,\n",
       "       [0],\n",
       "       [0],\n",
       "       [0]])"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Создание модели нейронной сети</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 12)                252       \n_________________________________________________________________\ndense_1 (Dense)              (None, 2)                 26        \n=================================================================\nTotal params: 278\nTrainable params: 278\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(12, activation='tanh', kernel_regularizer=tf.keras.regularizers.l2(0.01),\n",
    "                          input_shape=(20,)),\n",
    "    tf.keras.layers.Dense(2, activation='softmax')\n",
    "])\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 204,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[9.9888867e-01 1.1113590e-03]\n",
      " [9.9939823e-01 6.0171861e-04]\n",
      " [9.7778863e-01 2.2211321e-02]\n",
      " [9.9991632e-01 8.3627907e-05]\n",
      " [9.5554715e-01 4.4452846e-02]\n",
      " [9.9310726e-01 6.8927575e-03]\n",
      " [9.9917573e-01 8.2422997e-04]\n",
      " [9.9672639e-01 3.2735907e-03]\n",
      " [9.9872667e-01 1.2733137e-03]\n",
      " [9.9947780e-01 5.2216806e-04]]\n",
      "[0 0 0 0 0 0 0 0 0 0]\n",
      "[0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "y_pred = model.predict(data)\n",
    "print(y_pred[:10])\n",
    "y_pred = np.argmax(y_pred, axis=-1)\n",
    "print(y_pred[:10])\n",
    "print(labels[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Клонирование модели для transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense (Dense)                (None, 12)                252       \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2)                 26        \n",
      "=================================================================\n",
      "Total params: 278\n",
      "Trainable params: 278\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model('Джарвис.h5')\n",
    "model = tf.keras.models.clone_model(model)\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Обучение</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 000 -- Loss(SparseCategoricalCrossentropy): 0.002, Recall: 0.8710607886314392, Precision: 0.9353457689285278\nEpoch 010 -- Loss(SparseCategoricalCrossentropy): 0.001, Recall: 0.8718108534812927, Precision: 0.9357494711875916\nEpoch 020 -- Loss(SparseCategoricalCrossentropy): 0.001, Recall: 0.8725522756576538, Precision: 0.9361481666564941\nEpoch 030 -- Loss(SparseCategoricalCrossentropy): 0.001, Recall: 0.8732851147651672, Precision: 0.9365419149398804\nEpoch 040 -- Loss(SparseCategoricalCrossentropy): 0.001, Recall: 0.8740096092224121, Precision: 0.9369308352470398\nEpoch 050 -- Loss(SparseCategoricalCrossentropy): 0.001, Recall: 0.874725878238678, Precision: 0.937315046787262\nEpoch 060 -- Loss(SparseCategoricalCrossentropy): 0.001, Recall: 0.8754340410232544, Precision: 0.9376946091651917\nEpoch 070 -- Loss(SparseCategoricalCrossentropy): 0.001, Recall: 0.8761342763900757, Precision: 0.9380695819854736\nEpoch 080 -- Loss(SparseCategoricalCrossentropy): 0.001, Recall: 0.8768266439437866, Precision: 0.9384400844573975\nEpoch 090 -- Loss(SparseCategoricalCrossentropy): 0.001, Recall: 0.8775113224983215, Precision: 0.9388061761856079\nEpoch 100 -- Loss(SparseCategoricalCrossentropy): 0.001, Recall: 0.87818843126297, Precision: 0.9391679763793945\nEpoch 110 -- Loss(SparseCategoricalCrossentropy): 0.001, Recall: 0.8788580894470215, Precision: 0.9395254850387573\nEpoch 120 -- Loss(SparseCategoricalCrossentropy): 0.001, Recall: 0.8795204162597656, Precision: 0.9398788213729858\nEpoch 130 -- Loss(SparseCategoricalCrossentropy): 0.001, Recall: 0.8801755905151367, Precision: 0.9402280449867249\nEpoch 140 -- Loss(SparseCategoricalCrossentropy): 0.001, Recall: 0.8808236122131348, Precision: 0.9405732154846191\nEpoch 150 -- Loss(SparseCategoricalCrossentropy): 0.001, Recall: 0.8814646601676941, Precision: 0.9409144520759583\nEpoch 160 -- Loss(SparseCategoricalCrossentropy): 0.001, Recall: 0.882098913192749, Precision: 0.941251814365387\nEpoch 170 -- Loss(SparseCategoricalCrossentropy): 0.001, Recall: 0.8827263712882996, Precision: 0.9415853023529053\nEpoch 180 -- Loss(SparseCategoricalCrossentropy): 0.001, Recall: 0.88334721326828, Precision: 0.9419150352478027\nEpoch 190 -- Loss(SparseCategoricalCrossentropy): 0.001, Recall: 0.8839614987373352, Precision: 0.9422410726547241\nEpoch 200 -- Loss(SparseCategoricalCrossentropy): 0.001, Recall: 0.8845693469047546, Precision: 0.9425634741783142\n"
    }
   ],
   "source": [
    "tft.train(\n",
    "    train_dataset=dataset,\n",
    "    model=model,\n",
    "    epochs=200,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('Mira-v1.0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = tft.predict_classes(model=model, features=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "1070 1.0\n"
    }
   ],
   "source": [
    "n = 0\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    n += int(labels[i] == predictions[i])\n",
    "\n",
    "print(n, n / len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('venv': venv)",
   "language": "python",
   "name": "python_defaultSpec_1595177196542"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}