{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "qFi9FiWol1KT"
   },
   "outputs": [],
   "source": [
    "from preprocessing import Audio\n",
    "import tensorflow as tf\n",
    "import tf_train as tft\n",
    "import numpy as np\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy as sp\n",
    "import librosa as li\n",
    "import librosa.display\n",
    "import IPython.display as ipd\n",
    "\n",
    "%matplotlib inline\n",
    "#tf.debugging.set_log_device_placement(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "'/physical_device:GPU:0'"
     },
     "metadata": {},
     "execution_count": 2
    }
   ],
   "source": [
    "GPU = tf.config.list_physical_devices('GPU')\n",
    "CPU = tf.config.list_physical_devices('CPU')\n",
    "DEVICE = GPU[0].name if GPU else CPU[0].name\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Подготовка данных для обучения и тестирования</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    def norm(x):\n",
    "        std = np.std(x ,ddof=1)\n",
    "        return (x - np.mean(x)) / std\n",
    "\n",
    "    PATH_0 = r'AudioData/0 Данные' # negative class\n",
    "    PATH_1 = r'AudioData/1 Джарвис' # positive class\n",
    "    PATH_2 = r'AudioData/2 Дио' # positive class\n",
    "    PATH_3 = r'AudioData/3 Итан' # positive class\n",
    "    PATH_4 = r'AudioData/4 Лада' # positive class\n",
    "    PATH_5 = r'AudioData/5 Мира' # positive class\n",
    "\n",
    "    PATHS = li.util.find_files(PATH_0)[:3000] + li.util.find_files(PATH_1) + li.util.find_files(PATH_2) + li.util.find_files(PATH_3) + li.util.find_files(PATH_5) + li.util.find_files(PATH_5)\n",
    "    N = len(PATHS)\n",
    "\n",
    "    np.random.shuffle(PATHS)\n",
    "\n",
    "    SOUNDS = []\n",
    "    for path in PATHS:\n",
    "        SOUNDS.append(Audio(path))\n",
    "        print('Loading {:.1f}%'.format(len(SOUNDS) / N * 100))\n",
    "        ipd.clear_output(wait=True)\n",
    "    DATA = []\n",
    "    LABELS = []\n",
    "\n",
    "    for sound in SOUNDS:\n",
    "        DATA.append(norm(sound.e_parts))\n",
    "        LABELS.append(sound.label)\n",
    "\n",
    "    return (np.array(DATA), np.array(LABELS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Loading 100.0%\n"
    }
   ],
   "source": [
    "data, labels = get_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data, test_labels = data[8000:], labels[8000:]\n",
    "data, labels = data[:8000], labels[:8000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "((3361, 20), (3361,))"
     },
     "metadata": {},
     "execution_count": 5
    }
   ],
   "source": [
    "data.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<BatchDataset shapes: ((None, 20), (None,)), types: (tf.float64, tf.int32)>"
     },
     "metadata": {},
     "execution_count": 48
    }
   ],
   "source": [
    "BATCH_SIZE = 1081\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((data, labels))\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<BatchDataset shapes: ((None, 1, 20), (None,)), types: (tf.float64, tf.int32)>"
     },
     "metadata": {},
     "execution_count": 56
    }
   ],
   "source": [
    "BATCH_SIZE = 3361\n",
    "test_data = np.reshape(data, [3361, 1, 20])\n",
    "test_labels = np.reshape(labels, [1, 3361])\n",
    "\n",
    "dataset = tf.data.Dataset.from_tensor_slices((test_data, labels))\n",
    "dataset = dataset.batch(BATCH_SIZE)\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.reshape(data, (10070, 20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = np.reshape(labels, (10070,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([[0, 0, 0, ..., 0, 0, 0]])"
     },
     "metadata": {},
     "execution_count": 58
    }
   ],
   "source": [
    "test_labels[:100]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Создание модели нейронной сети</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:Layer gru_4 will not use cuDNN kernel since it doesn't meet the cuDNN kernel criteria. It will use generic GPU kernel as fallback when running on GPU\nModel: \"All_GRU\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ngru_4 (GRU)                  (None, 20)                2460      \n_________________________________________________________________\ndense_4 (Dense)              (None, 6)                 126       \n=================================================================\nTotal params: 2,586\nTrainable params: 2,586\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer(input_shape=(1, 20,)),\n",
    "    tf.keras.layers.GRU(20, kernel_regularizer=tf.keras.regularizers.l2(0.01), reset_after=False),\n",
    "    # tf.keras.layers.Dense(100, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    # tf.keras.layers.Dense(50, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    # tf.keras.layers.Dense(25, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    # tf.keras.layers.Dense(12, activation=\"relu\", kernel_regularizer=tf.keras.regularizers.l2(0.01)),\n",
    "    tf.keras.layers.Dense(6)\n",
    "], name='All_GRU')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "PhysicalDevice(name='/physical_device:CPU:0', device_type='CPU')"
     },
     "metadata": {},
     "execution_count": 10
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Обучение</h1>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "Epoch 000 -- Loss(SparseCategoricalCrossentropy): 0.583, Accuracy: 0.8893186450004578\nEpoch 010 -- Loss(SparseCategoricalCrossentropy): 0.578, Accuracy: 0.8893186450004578\nEpoch 020 -- Loss(SparseCategoricalCrossentropy): 0.573, Accuracy: 0.8893186450004578\nEpoch 030 -- Loss(SparseCategoricalCrossentropy): 0.568, Accuracy: 0.8893186450004578\nEpoch 040 -- Loss(SparseCategoricalCrossentropy): 0.564, Accuracy: 0.8893404006958008\nEpoch 050 -- Loss(SparseCategoricalCrossentropy): 0.559, Accuracy: 0.8893945217132568\nEpoch 060 -- Loss(SparseCategoricalCrossentropy): 0.555, Accuracy: 0.889430820941925\nEpoch 070 -- Loss(SparseCategoricalCrossentropy): 0.551, Accuracy: 0.8894569277763367\nEpoch 080 -- Loss(SparseCategoricalCrossentropy): 0.547, Accuracy: 0.8894765973091125\nEpoch 090 -- Loss(SparseCategoricalCrossentropy): 0.543, Accuracy: 0.8894919157028198\nEpoch 100 -- Loss(SparseCategoricalCrossentropy): 0.539, Accuracy: 0.8895101547241211\nEpoch 110 -- Loss(SparseCategoricalCrossentropy): 0.536, Accuracy: 0.8895465135574341\nEpoch 120 -- Loss(SparseCategoricalCrossentropy): 0.532, Accuracy: 0.8895989656448364\nEpoch 130 -- Loss(SparseCategoricalCrossentropy): 0.529, Accuracy: 0.8896456956863403\nEpoch 140 -- Loss(SparseCategoricalCrossentropy): 0.526, Accuracy: 0.8896858096122742\nEpoch 150 -- Loss(SparseCategoricalCrossentropy): 0.523, Accuracy: 0.889720618724823\nEpoch 160 -- Loss(SparseCategoricalCrossentropy): 0.520, Accuracy: 0.8897510766983032\nEpoch 170 -- Loss(SparseCategoricalCrossentropy): 0.517, Accuracy: 0.8897780179977417\nEpoch 180 -- Loss(SparseCategoricalCrossentropy): 0.514, Accuracy: 0.8898183703422546\nEpoch 190 -- Loss(SparseCategoricalCrossentropy): 0.512, Accuracy: 0.8898545503616333\nEpoch 200 -- Loss(SparseCategoricalCrossentropy): 0.509, Accuracy: 0.8898870944976807\nEpoch 210 -- Loss(SparseCategoricalCrossentropy): 0.507, Accuracy: 0.8899165391921997\nEpoch 220 -- Loss(SparseCategoricalCrossentropy): 0.504, Accuracy: 0.8899433612823486\nEpoch 230 -- Loss(SparseCategoricalCrossentropy): 0.502, Accuracy: 0.8899677991867065\nEpoch 240 -- Loss(SparseCategoricalCrossentropy): 0.500, Accuracy: 0.8899902701377869\nEpoch 250 -- Loss(SparseCategoricalCrossentropy): 0.498, Accuracy: 0.8900108933448792\nEpoch 260 -- Loss(SparseCategoricalCrossentropy): 0.495, Accuracy: 0.8900414109230042\nEpoch 270 -- Loss(SparseCategoricalCrossentropy): 0.493, Accuracy: 0.8900696039199829\nEpoch 280 -- Loss(SparseCategoricalCrossentropy): 0.491, Accuracy: 0.8900958299636841\nEpoch 290 -- Loss(SparseCategoricalCrossentropy): 0.489, Accuracy: 0.890120267868042\nEpoch 300 -- Loss(SparseCategoricalCrossentropy): 0.488, Accuracy: 0.8901430368423462\nEpoch 310 -- Loss(SparseCategoricalCrossentropy): 0.486, Accuracy: 0.8901643753051758\nEpoch 320 -- Loss(SparseCategoricalCrossentropy): 0.484, Accuracy: 0.8901843428611755\nEpoch 330 -- Loss(SparseCategoricalCrossentropy): 0.482, Accuracy: 0.8902031779289246\nEpoch 340 -- Loss(SparseCategoricalCrossentropy): 0.480, Accuracy: 0.8902208209037781\nEpoch 350 -- Loss(SparseCategoricalCrossentropy): 0.479, Accuracy: 0.8902375102043152\nEpoch 360 -- Loss(SparseCategoricalCrossentropy): 0.477, Accuracy: 0.8902533054351807\nEpoch 370 -- Loss(SparseCategoricalCrossentropy): 0.476, Accuracy: 0.8902682065963745\nEpoch 380 -- Loss(SparseCategoricalCrossentropy): 0.474, Accuracy: 0.8902823328971863\nEpoch 390 -- Loss(SparseCategoricalCrossentropy): 0.473, Accuracy: 0.890295684337616\nEpoch 400 -- Loss(SparseCategoricalCrossentropy): 0.471, Accuracy: 0.8903114199638367\nEpoch 410 -- Loss(SparseCategoricalCrossentropy): 0.470, Accuracy: 0.8903306722640991\nEpoch 420 -- Loss(SparseCategoricalCrossentropy): 0.468, Accuracy: 0.8903490304946899\nEpoch 430 -- Loss(SparseCategoricalCrossentropy): 0.467, Accuracy: 0.8903665542602539\nEpoch 440 -- Loss(SparseCategoricalCrossentropy): 0.466, Accuracy: 0.8903833031654358\nEpoch 450 -- Loss(SparseCategoricalCrossentropy): 0.464, Accuracy: 0.8904018998146057\nEpoch 460 -- Loss(SparseCategoricalCrossentropy): 0.463, Accuracy: 0.890423595905304\nEpoch 470 -- Loss(SparseCategoricalCrossentropy): 0.462, Accuracy: 0.8904468417167664\nEpoch 480 -- Loss(SparseCategoricalCrossentropy): 0.461, Accuracy: 0.8904728889465332\nEpoch 490 -- Loss(SparseCategoricalCrossentropy): 0.459, Accuracy: 0.8904978632926941\nEpoch 500 -- Loss(SparseCategoricalCrossentropy): 0.458, Accuracy: 0.8905218243598938\nEpoch 510 -- Loss(SparseCategoricalCrossentropy): 0.457, Accuracy: 0.8905489444732666\nEpoch 520 -- Loss(SparseCategoricalCrossentropy): 0.456, Accuracy: 0.8905767202377319\nEpoch 530 -- Loss(SparseCategoricalCrossentropy): 0.455, Accuracy: 0.8906034827232361\nEpoch 540 -- Loss(SparseCategoricalCrossentropy): 0.454, Accuracy: 0.890629231929779\nEpoch 550 -- Loss(SparseCategoricalCrossentropy): 0.453, Accuracy: 0.8906540274620056\nEpoch 560 -- Loss(SparseCategoricalCrossentropy): 0.452, Accuracy: 0.8906779885292053\nEpoch 570 -- Loss(SparseCategoricalCrossentropy): 0.451, Accuracy: 0.8907010555267334\nEpoch 580 -- Loss(SparseCategoricalCrossentropy): 0.450, Accuracy: 0.8907233476638794\nEpoch 590 -- Loss(SparseCategoricalCrossentropy): 0.449, Accuracy: 0.8907448649406433\nEpoch 600 -- Loss(SparseCategoricalCrossentropy): 0.448, Accuracy: 0.8907657265663147\nEpoch 610 -- Loss(SparseCategoricalCrossentropy): 0.447, Accuracy: 0.8907858729362488\nEpoch 620 -- Loss(SparseCategoricalCrossentropy): 0.446, Accuracy: 0.8908053636550903\nEpoch 630 -- Loss(SparseCategoricalCrossentropy): 0.445, Accuracy: 0.8908241987228394\nEpoch 640 -- Loss(SparseCategoricalCrossentropy): 0.444, Accuracy: 0.8908424973487854\nEpoch 650 -- Loss(SparseCategoricalCrossentropy): 0.443, Accuracy: 0.8908602595329285\nEpoch 660 -- Loss(SparseCategoricalCrossentropy): 0.442, Accuracy: 0.8908774256706238\nEpoch 670 -- Loss(SparseCategoricalCrossentropy): 0.441, Accuracy: 0.8908941149711609\nEpoch 680 -- Loss(SparseCategoricalCrossentropy): 0.440, Accuracy: 0.890910267829895\nEpoch 690 -- Loss(SparseCategoricalCrossentropy): 0.439, Accuracy: 0.8909260034561157\nEpoch 700 -- Loss(SparseCategoricalCrossentropy): 0.439, Accuracy: 0.8909412622451782\nEpoch 710 -- Loss(SparseCategoricalCrossentropy): 0.438, Accuracy: 0.8909561038017273\nEpoch 720 -- Loss(SparseCategoricalCrossentropy): 0.437, Accuracy: 0.8909705281257629\nEpoch 730 -- Loss(SparseCategoricalCrossentropy): 0.436, Accuracy: 0.8909845948219299\nEpoch 740 -- Loss(SparseCategoricalCrossentropy): 0.435, Accuracy: 0.8909982442855835\nEpoch 750 -- Loss(SparseCategoricalCrossentropy): 0.434, Accuracy: 0.8910115361213684\nEpoch 760 -- Loss(SparseCategoricalCrossentropy): 0.434, Accuracy: 0.8910244703292847\nEpoch 770 -- Loss(SparseCategoricalCrossentropy): 0.433, Accuracy: 0.891037106513977\nEpoch 780 -- Loss(SparseCategoricalCrossentropy): 0.432, Accuracy: 0.8910493850708008\nEpoch 790 -- Loss(SparseCategoricalCrossentropy): 0.431, Accuracy: 0.8910613059997559\nEpoch 800 -- Loss(SparseCategoricalCrossentropy): 0.430, Accuracy: 0.8910729885101318\nEpoch 810 -- Loss(SparseCategoricalCrossentropy): 0.430, Accuracy: 0.8910843729972839\nEpoch 820 -- Loss(SparseCategoricalCrossentropy): 0.429, Accuracy: 0.8910955190658569\nEpoch 830 -- Loss(SparseCategoricalCrossentropy): 0.428, Accuracy: 0.891106367111206\nEpoch 840 -- Loss(SparseCategoricalCrossentropy): 0.427, Accuracy: 0.8911169171333313\nEpoch 850 -- Loss(SparseCategoricalCrossentropy): 0.427, Accuracy: 0.8911272883415222\nEpoch 860 -- Loss(SparseCategoricalCrossentropy): 0.426, Accuracy: 0.8911373615264893\nEpoch 870 -- Loss(SparseCategoricalCrossentropy): 0.425, Accuracy: 0.8911471962928772\nEpoch 880 -- Loss(SparseCategoricalCrossentropy): 0.424, Accuracy: 0.8911568522453308\nEpoch 890 -- Loss(SparseCategoricalCrossentropy): 0.424, Accuracy: 0.8911662697792053\nEpoch 900 -- Loss(SparseCategoricalCrossentropy): 0.423, Accuracy: 0.8911755084991455\nEpoch 910 -- Loss(SparseCategoricalCrossentropy): 0.422, Accuracy: 0.8911845088005066\nEpoch 920 -- Loss(SparseCategoricalCrossentropy): 0.421, Accuracy: 0.8911991119384766\nEpoch 930 -- Loss(SparseCategoricalCrossentropy): 0.421, Accuracy: 0.8912140727043152\nEpoch 940 -- Loss(SparseCategoricalCrossentropy): 0.420, Accuracy: 0.8912287354469299\nEpoch 950 -- Loss(SparseCategoricalCrossentropy): 0.419, Accuracy: 0.891243040561676\nEpoch 960 -- Loss(SparseCategoricalCrossentropy): 0.418, Accuracy: 0.891257107257843\nEpoch 970 -- Loss(SparseCategoricalCrossentropy): 0.418, Accuracy: 0.8912708163261414\nEpoch 980 -- Loss(SparseCategoricalCrossentropy): 0.417, Accuracy: 0.8912842869758606\nEpoch 990 -- Loss(SparseCategoricalCrossentropy): 0.416, Accuracy: 0.891297459602356\nEpoch 1000 -- Loss(SparseCategoricalCrossentropy): 0.416, Accuracy: 0.8913103938102722\n"
    }
   ],
   "source": [
    "tft.train(\n",
    "    train_dataset=dataset,\n",
    "    model=model,\n",
    "    epochs=1000,\n",
    "    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models\\{}-v1.0.h5'.format(model.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "WARNING:tensorflow:No training configuration found in the save file, so the model was *not* compiled. Compile it manually.\nModel: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\ndense (Dense)                (None, 12)                252       \n_________________________________________________________________\ndense_1 (Dense)              (None, 2)                 26        \n=================================================================\nTotal params: 278\nTrainable params: 278\nNon-trainable params: 0\n_________________________________________________________________\n"
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(r'models\\Mira-v1.0.h5')\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "with tf.device(\"CPU\"):\n",
    "    predictions = tft.predict_classes(model=model, features=test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "3361 100.0\n"
    }
   ],
   "source": [
    "n = 0\n",
    "\n",
    "for i in range(len(labels)):\n",
    "    n += int(labels[i] == predictions[i])\n",
    "\n",
    "print(n, n / len(labels) * 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(<tf.Tensor: shape=(10,), dtype=int64, numpy=array([0, 0, 1, 1, 0, 0, 0, 0, 3, 0], dtype=int64)>,\n array([0, 0, 1, 1, 0, 0, 0, 0, 3, 0]))"
     },
     "metadata": {},
     "execution_count": 41
    }
   ],
   "source": [
    "predictions[60:70], labels[60:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(<tf.Tensor: shape=(15,), dtype=int64, numpy=array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0], dtype=int64)>,\n array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]))"
     },
     "metadata": {},
     "execution_count": 40
    }
   ],
   "source": [
    "predictions[:15], labels[:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "array([0, 0, 0, 0, 0, 0, 0, 0, 0, 0])"
     },
     "metadata": {},
     "execution_count": 30
    }
   ],
   "source": [
    "labels[60:70]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'test.tfrecord'\n",
    "writer_data = tf.data.experimental.TFRecordWriter(\"datasets\\Mira\\data.tfrecord\")\n",
    "writer_labels = tf.data.experimental.TFRecordWriter(\"datasets\\Mira\\labels.tfrecord\")\n",
    "test_data = tf.data.Dataset.from_tensor_slices(data)\n",
    "test_labels = tf.data.Dataset.from_tensor_slices(labels)\n",
    "test_data = test_data.map(lambda x: str(x))\n",
    "test_labels = test_labels.map(lambda x: str(x))\n",
    "writer_data.write(test_data)\n",
    "writer_labels.write(test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_dataset = tf.data.TFRecordDataset([\"datasets\\Mira\\labels.tfrecord\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "tf.Tensor(b'Tensor(\"args_0:0\", shape=(), dtype=int32)', shape=(), dtype=string)\n"
    }
   ],
   "source": [
    "for d in loaded_dataset.take(1):\n",
    "    print(d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<TFRecordDatasetV2 shapes: (), types: tf.string>"
     },
     "metadata": {},
     "execution_count": 77
    }
   ],
   "source": [
    "loaded_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": "b'Tensor(\"args_0:0\", shape=(20,), dtype=float64)'\n"
    }
   ],
   "source": [
    "for d in test_data.take(1):\n",
    "    print(d.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "error",
     "ename": "InvalidArgumentError",
     "evalue": "predictions must be <= 1\nCondition x <= y did not hold.\nFirst 3 elements of x:\n[1. 0. 1.]\nFirst 1 elements of y:\n[1.]",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-74-f23c066cb68c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mRecall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mclass_id\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[1;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_context_for_symbolic_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m       \u001b[0mupdate_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_state_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# update_op will be None in eager execution.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m       \u001b[0mmetric_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mupdate_state\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m   1380\u001b[0m       \u001b[0mUpdate\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1381\u001b[0m     \"\"\"\n\u001b[1;32m-> 1382\u001b[1;33m     return metrics_utils.update_confusion_matrix_variables(\n\u001b[0m\u001b[0;32m   1383\u001b[0m         {\n\u001b[0;32m   1384\u001b[0m             \u001b[0mmetrics_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mConfusionMatrix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRUE_POSITIVES\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrue_positives\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\metrics_utils.py\u001b[0m in \u001b[0;36mupdate_confusion_matrix_variables\u001b[1;34m(variables_to_update, y_true, y_pred, thresholds, top_k, class_id, sample_weight, multi_label, label_weights)\u001b[0m\n\u001b[0;32m    337\u001b[0m           \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m           message='predictions must be >= 0'),\n\u001b[1;32m--> 339\u001b[1;33m       check_ops.assert_less_equal(\n\u001b[0m\u001b[0;32m    340\u001b[0m           \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m           \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\check_ops.py\u001b[0m in \u001b[0;36massert_less_equal\u001b[1;34m(x, y, data, summarize, message, name)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_binary_assert_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<='\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0massert_less_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 923\u001b[1;33m   return _binary_assert('<=', 'assert_less_equal', math_ops.less_equal,\n\u001b[0m\u001b[0;32m    924\u001b[0m                         np.less_equal, x, y, data, summarize, message, name)\n\u001b[0;32m    925\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\check_ops.py\u001b[0m in \u001b[0;36m_binary_assert\u001b[1;34m(sym, opname, op_func, static_func, x, y, data, summarize, message, name)\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m       raise errors.InvalidArgumentError(\n\u001b[0m\u001b[0;32m    353\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m           \u001b[0mop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: predictions must be <= 1\nCondition x <= y did not hold.\nFirst 3 elements of x:\n[1. 0. 1.]\nFirst 1 elements of y:\n[1.]"
     ]
    }
   ],
   "source": [
    "m = tf.keras.metrics.Recall(class_id=1)\n",
    "m.update_state([1, 0, 1, 2], [1, 0, 1, 2])\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "<tf.Tensor: shape=(6,), dtype=float32, numpy=\narray([0.98039216, 0.00272254, 0.00372326, 0.00742231, 0.00221274,\n       0.00352691], dtype=float32)>"
     },
     "metadata": {},
     "execution_count": 82
    }
   ],
   "source": [
    "y_pred = tf.nn.softmax(model(test_data[:1]))[0]\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "output_type": "error",
     "ename": "InvalidArgumentError",
     "evalue": "predictions must be <= 1\nCondition x <= y did not hold.\nFirst 3 elements of x:\n[1. 2. 3.]\nFirst 1 elements of y:\n[1.]",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-98-a1e5f06a2b2b>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mm\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTruePositives\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mupdate_state\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      3\u001b[0m \u001b[0mm\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumpy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\metrics_utils.py\u001b[0m in \u001b[0;36mdecorated\u001b[1;34m(metric_obj, *args, **kwargs)\u001b[0m\n\u001b[0;32m     88\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     89\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mgraph_context_for_symbolic_tensors\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 90\u001b[1;33m       \u001b[0mupdate_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mupdate_state_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     91\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mupdate_op\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# update_op will be None in eager execution.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     92\u001b[0m       \u001b[0mmetric_obj\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\metrics.py\u001b[0m in \u001b[0;36mupdate_state\u001b[1;34m(self, y_true, y_pred, sample_weight)\u001b[0m\n\u001b[0;32m    934\u001b[0m       \u001b[0mUpdate\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    935\u001b[0m     \"\"\"\n\u001b[1;32m--> 936\u001b[1;33m     return metrics_utils.update_confusion_matrix_variables(\n\u001b[0m\u001b[0;32m    937\u001b[0m         \u001b[1;33m{\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_confusion_matrix_cond\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0maccumulator\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    938\u001b[0m         \u001b[0my_true\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\keras\\utils\\metrics_utils.py\u001b[0m in \u001b[0;36mupdate_confusion_matrix_variables\u001b[1;34m(variables_to_update, y_true, y_pred, thresholds, top_k, class_id, sample_weight, multi_label, label_weights)\u001b[0m\n\u001b[0;32m    337\u001b[0m           \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    338\u001b[0m           message='predictions must be >= 0'),\n\u001b[1;32m--> 339\u001b[1;33m       check_ops.assert_less_equal(\n\u001b[0m\u001b[0;32m    340\u001b[0m           \u001b[0my_pred\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    341\u001b[0m           \u001b[0mmath_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcast\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1.0\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my_pred\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\check_ops.py\u001b[0m in \u001b[0;36massert_less_equal\u001b[1;34m(x, y, data, summarize, message, name)\u001b[0m\n\u001b[0;32m    921\u001b[0m \u001b[1;33m@\u001b[0m\u001b[0m_binary_assert_doc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'<='\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0massert_less_equal\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msummarize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 923\u001b[1;33m   return _binary_assert('<=', 'assert_less_equal', math_ops.less_equal,\n\u001b[0m\u001b[0;32m    924\u001b[0m                         np.less_equal, x, y, data, summarize, message, name)\n\u001b[0;32m    925\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32md:\\Work\\AudioRec\\venv\\lib\\site-packages\\tensorflow\\python\\ops\\check_ops.py\u001b[0m in \u001b[0;36m_binary_assert\u001b[1;34m(sym, opname, op_func, static_func, x, y, data, summarize, message, name)\u001b[0m\n\u001b[0;32m    350\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mmessage\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    351\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 352\u001b[1;33m       raise errors.InvalidArgumentError(\n\u001b[0m\u001b[0;32m    353\u001b[0m           \u001b[0mnode_def\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    354\u001b[0m           \u001b[0mop\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: predictions must be <= 1\nCondition x <= y did not hold.\nFirst 3 elements of x:\n[1. 2. 3.]\nFirst 1 elements of y:\n[1.]"
     ]
    }
   ],
   "source": [
    "m = tf.keras.metrics.TruePositives()\n",
    "m.update_state([1, 2, 3], [1, 2, 3])\n",
    "m.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": "(<tf.Tensor: shape=(100,), dtype=int64, numpy=\n array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 3,\n        0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n        0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0], dtype=int64)>,\n array([0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 5, 0, 0, 0, 3,\n        0, 0, 0, 0, 0, 0, 0, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0,\n        0, 0, 3, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n        0, 0, 5, 0, 0, 0, 0, 0, 0, 0, 0, 0]))"
     },
     "metadata": {},
     "execution_count": 94
    }
   ],
   "source": [
    "predictions[:100], labels[:100]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Untitled0.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3.8.3 64-bit ('venv': venv)",
   "language": "python",
   "name": "python_defaultSpec_1596033945932"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}