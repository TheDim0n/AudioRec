{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/physical_device:GPU:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa as li\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from preprocessing import Audio\n",
    "\n",
    "%matplotlib inline\n",
    "GPU = tf.config.list_physical_devices('GPU')\n",
    "CPU = tf.config.list_physical_devices('CPU')\n",
    "DEVICE = GPU[0].name if GPU else CPU[0].name\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_len(y, sec=1.0, sr=16000):\n",
    "    y, _ = li.effects.trim(y)\n",
    "    x = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        [y],\n",
    "        maxlen=int(sr * sec),\n",
    "        padding='post',\n",
    "        truncating='post',\n",
    "        dtype='float32'\n",
    "    )[0]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(path):\n",
    "    audio = Audio(path)\n",
    "    augmented = audio.augmented()\n",
    "    #augmented = [audio.data]\n",
    "    #data = list(map(to_len, augmented))\n",
    "    labels = [audio.label] * len(augmented)\n",
    "    return [augmented, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labeled_data(nums=1500):\n",
    "    FALSE_DATA = 'AudioData/0 Данные'\n",
    "    NOISE = 'AudioData/0 Шум'\n",
    "    JARVIS = 'AudioData/1 Джарвис'\n",
    "    DIO = 'AudioData/2 Дио'\n",
    "    ITAN = 'AudioData/3 Итан'\n",
    "    LADA = 'AudioData/4 Лада'\n",
    "    MIRA = 'AudioData/5 Мира'\n",
    "    \n",
    "    p = li.util.find_files(FALSE_DATA)\n",
    "    np.random.shuffle(p)\n",
    "    PATHS = li.util.find_files(MIRA) + li.util.find_files(NOISE) + p[:nums]\n",
    "    \n",
    "    np.random.shuffle(PATHS)\n",
    "    \n",
    "    START_TIME = time.time()\n",
    "    \n",
    "    data = list()\n",
    "    labels = list()\n",
    "    \n",
    "    with ThreadPoolExecutor(32) as pool:\n",
    "        DATA = list(pool.map(get_audio, PATHS))\n",
    "    \n",
    "    for d, l in DATA:\n",
    "        data += d\n",
    "        labels += l\n",
    "\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    data = np.reshape(data, [*data.shape, 1])\n",
    "    labels = np.reshape(labels, [*labels.shape, 1])\n",
    "    print('Loading at {:.2f} seconds'.format(time.time()-START_TIME))\n",
    "    return (data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading at 292.34 seconds\n"
     ]
    }
   ],
   "source": [
    "data, labels = get_labeled_data(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11411, 200, 1), (11411, 1))"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=936>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=324>)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN = 9000\n",
    "tf.math.reduce_sum(labels[:TRAIN]), tf.math.reduce_sum(labels[TRAIN:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 200, 1), (None, 1)), types: (tf.float64, tf.int32)>\n",
      "<BatchDataset shapes: ((None, 200, 1), (None, 1)), types: (tf.float64, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((data[:TRAIN], labels[:TRAIN]))\n",
    "train_dataset = train_dataset.batch(64)\n",
    "print(train_dataset)\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((data[TRAIN:], labels[TRAIN:]))\n",
    "validation_dataset = validation_dataset.batch(64)\n",
    "print(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9024\n",
      "2432\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset) * 64)\n",
    "print(len(validation_dataset) * 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_model = tf.keras.models.load_model('models/conv/RootModel-v3.0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MiraConvV3.0\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv1d_3 (Conv1D)            (None, 16000, 1)          10        \n",
      "_________________________________________________________________\n",
      "dropout (Dropout)            (None, 16000, 1)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_4 (Conv1D)            (None, 16000, 20)         2000      \n",
      "_________________________________________________________________\n",
      "dropout_1 (Dropout)          (None, 16000, 20)         0         \n",
      "_________________________________________________________________\n",
      "conv1d_5 (Conv1D)            (None, 40, 10)            80000     \n",
      "_________________________________________________________________\n",
      "dropout_2 (Dropout)          (None, 40, 10)            0         \n",
      "_________________________________________________________________\n",
      "flatten_1 (Flatten)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 1, 400)            0         \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 1, 400)            1600      \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 400)               962400    \n",
      "_________________________________________________________________\n",
      "dropout_3 (Dropout)          (None, 400)               0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 401       \n",
      "=================================================================\n",
      "Total params: 1,046,411\n",
      "Trainable params: 1,045,611\n",
      "Non-trainable params: 800\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.clone_model(root_model)\n",
    "model._name = 'MiraConvV3.0'\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MiraGRUV4.3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization_2 (Normalizati (None, 200, 1)            3         \n",
      "_________________________________________________________________\n",
      "gru_22 (GRU)                 (None, 200)               121800    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 122,004\n",
      "Trainable params: 122,001\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.InputLayer((200, 1)),\n",
    "    tf.keras.layers.experimental.preprocessing.Normalization(),\n",
    "    tf.keras.layers.GRU(200, kernel_regularizer=tf.keras.regularizers.l2(0.001)),\n",
    "    \n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "], name='MiraGRUV4.3')\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.Recall(name='rec'),\n",
    "        tf.keras.metrics.Precision(name='prec'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "141/141 - 2s - loss: 0.0069 - rec: 1.0000 - prec: 0.9926\n",
      "Epoch 2/5\n",
      "141/141 - 2s - loss: 0.0110 - rec: 0.9936 - prec: 0.9820\n",
      "Epoch 3/5\n",
      "141/141 - 2s - loss: 0.0094 - rec: 0.9925 - prec: 0.9862\n",
      "Epoch 4/5\n",
      "141/141 - 2s - loss: 0.0201 - rec: 0.9861 - prec: 0.9585\n",
      "Epoch 5/5\n",
      "141/141 - 2s - loss: 0.0109 - rec: 0.9915 - prec: 0.9820\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1d73b4790c8>"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=5,\n",
    "    verbose=2,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 - 0s - loss: 0.0624 - rec: 0.8920 - prec: 0.9797\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.062373436987400055, 0.8919752836227417, 0.9796609878540039]"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_dataset, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/v4/{}.3.h5'.format(model.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 - 0s - loss: 0.1175 - rec: 0.7623 - prec: 1.0000\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.11749754846096039, 0.7623456716537476, 1.0]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_dataset, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [],
   "source": [
    "tested_model = tf.keras.models.load_model('models/v4/MiraGRUV4.3.2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MiraGRUV4.3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "normalization_2 (Normalizati (None, 200, 1)            3         \n",
      "_________________________________________________________________\n",
      "gru_22 (GRU)                 (None, 200)               121800    \n",
      "_________________________________________________________________\n",
      "dense_22 (Dense)             (None, 1)                 201       \n",
      "=================================================================\n",
      "Total params: 122,004\n",
      "Trainable params: 122,001\n",
      "Non-trainable params: 3\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tested_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "141/141 [==============================] - 1s 7ms/step - loss: 0.0445 - rec: 0.9573 - prec: 0.9324\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.044500984251499176, 0.9572649598121643, 0.9323621392250061]"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tested_model.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "38/38 [==============================] - 0s 8ms/step - loss: 0.0430 - rec: 0.9630 - prec: 0.9483\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04298418387770653, 0.9629629850387573, 0.9483282566070557]"
      ]
     },
     "execution_count": 240,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tested_model.evaluate(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9827519]], dtype=float32)"
      ]
     },
     "execution_count": 232,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tested_model.predict(np.reshape(data[10000],(1, 200)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "tested_model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.Recall(name='rec'),\n",
    "        tf.keras.metrics.Precision(name='prec'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200, 1)"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1])"
      ]
     },
     "execution_count": 233,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[10000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "tested_model.layers[0].reset_after = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [],
   "source": [
    "tested_model.save('models/v4/MiraGRUV4.3.2-1.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audiorec",
   "language": "python",
   "name": "audiorec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
