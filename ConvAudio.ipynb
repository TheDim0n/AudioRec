{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/physical_device:GPU:0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import librosa as li\n",
    "import matplotlib.pyplot as plt\n",
    "import IPython.display as ipd\n",
    "import time\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "from preprocessing import Audio\n",
    "\n",
    "%matplotlib inline\n",
    "GPU = tf.config.list_physical_devices('GPU')\n",
    "CPU = tf.config.list_physical_devices('CPU')\n",
    "DEVICE = GPU[0].name if GPU else CPU[0].name\n",
    "DEVICE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_len(y, sec=1.0, sr=44100):\n",
    "    y, _ = li.effects.trim(y)\n",
    "    x = tf.keras.preprocessing.sequence.pad_sequences(\n",
    "        [y],\n",
    "        maxlen=int(sr * sec),\n",
    "        padding='post',\n",
    "        truncating='post',\n",
    "        dtype='float32'\n",
    "    )[0]\n",
    "    return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio(path):\n",
    "    audio = Audio(path)\n",
    "    augmented = audio.augmented_source()\n",
    "    data = list(map(to_len, augmented))\n",
    "    labels = [audio.label] * len(augmented)\n",
    "    return [data, labels]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_labeled_data(nums=1500):\n",
    "    FALSE_DATA = 'AudioData/0 Данные'\n",
    "    NOISE = 'AudioData/0 Шум'\n",
    "    JARVIS = 'AudioData/1 Джарвис'\n",
    "    DIO = 'AudioData/2 Дио'\n",
    "    ITAN = 'AudioData/3 Итан'\n",
    "    LADA = 'AudioData/4 Лада'\n",
    "    MIRA = 'AudioData/5 Мира'\n",
    "    \n",
    "    p = li.util.find_files(FALSE_DATA)\n",
    "    np.random.shuffle(p)\n",
    "    PATHS = li.util.find_files(LADA) + li.util.find_files(NOISE) + p[:nums]\n",
    "    \n",
    "    np.random.shuffle(PATHS)\n",
    "    \n",
    "    START_TIME = time.time()\n",
    "    \n",
    "    data = list()\n",
    "    labels = list()\n",
    "    \n",
    "    with ThreadPoolExecutor(32) as pool:\n",
    "        DATA = list(pool.map(get_audio, PATHS))\n",
    "    \n",
    "    for d, l in DATA:\n",
    "        data += d\n",
    "        labels += l\n",
    "\n",
    "    data = np.array(data)\n",
    "    labels = np.array(labels)\n",
    "    data = np.reshape(data, [*data.shape, 1])\n",
    "    labels = np.reshape(labels, [*labels.shape, 1])\n",
    "    print('Loading at {:.2f} seconds'.format(time.time()-START_TIME))\n",
    "    return (data, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading at 203.13 seconds\n"
     ]
    }
   ],
   "source": [
    "data, labels = get_labeled_data(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((11447, 44100, 1), (11447, 1))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape, labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(<tf.Tensor: shape=(), dtype=int32, numpy=1008>,\n",
       " <tf.Tensor: shape=(), dtype=int32, numpy=288>)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TRAIN = 9000\n",
    "tf.math.reduce_sum(labels[:TRAIN]), tf.math.reduce_sum(labels[TRAIN:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset shapes: ((None, 44100, 1), (None, 1)), types: (tf.float32, tf.int32)>\n",
      "<BatchDataset shapes: ((None, 44100, 1), (None, 1)), types: (tf.float32, tf.int32)>\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((data[:TRAIN], labels[:TRAIN]))\n",
    "train_dataset = train_dataset.batch(64)\n",
    "print(train_dataset)\n",
    "\n",
    "validation_dataset = tf.data.Dataset.from_tensor_slices((data[TRAIN:], labels[TRAIN:]))\n",
    "validation_dataset = validation_dataset.batch(64)\n",
    "print(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9024\n",
      "2496\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset) * 64)\n",
    "print(len(validation_dataset) * 64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "root_model = tf.keras.models.load_model('models/conv/RootModel-v2.0.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"LadaConvV2.2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_10 (Reshape)         (None, 4410, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 441, 10)           1000      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 441, 10)           0         \n",
      "_________________________________________________________________\n",
      "re_lu_17 (ReLU)              (None, 441, 10)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 21, 10)            2100      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 21, 10)            0         \n",
      "_________________________________________________________________\n",
      "re_lu_18 (ReLU)              (None, 21, 10)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 1, 10)             2100      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1, 10)             0         \n",
      "_________________________________________________________________\n",
      "re_lu_19 (ReLU)              (None, 1, 10)             0         \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 10)                660       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 5,871\n",
      "Trainable params: 5,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.clone_model(root_model)\n",
    "model._name = 'LadaConvV2.2'\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer=tf.keras.optimizers.Adam(),\n",
    "    loss=tf.keras.losses.BinaryCrossentropy(),\n",
    "    metrics=[\n",
    "        tf.keras.metrics.Recall(name='rec'),\n",
    "        tf.keras.metrics.Precision(name='prec'),\n",
    "        tf.keras.metrics.AUC(name='auc'),\n",
    "        tf.keras.metrics.BinaryAccuracy(name='acc'),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/30\n",
      "141/141 - 2s - loss: 0.0168 - rec: 0.9762 - prec: 0.9830 - auc: 0.9954 - acc: 0.9954\n",
      "Epoch 2/30\n",
      "141/141 - 2s - loss: 0.0164 - rec: 0.9792 - prec: 0.9890 - auc: 0.9967 - acc: 0.9964\n",
      "Epoch 3/30\n",
      "141/141 - 2s - loss: 0.0153 - rec: 0.9802 - prec: 0.9950 - auc: 0.9945 - acc: 0.9972\n",
      "Epoch 4/30\n",
      "141/141 - 2s - loss: 0.0143 - rec: 0.9802 - prec: 0.9910 - auc: 0.9965 - acc: 0.9968\n",
      "Epoch 5/30\n",
      "141/141 - 2s - loss: 0.0149 - rec: 0.9812 - prec: 0.9851 - auc: 0.9965 - acc: 0.9962\n",
      "Epoch 6/30\n",
      "141/141 - 2s - loss: 0.0137 - rec: 0.9802 - prec: 0.9940 - auc: 0.9956 - acc: 0.9971\n",
      "Epoch 7/30\n",
      "141/141 - 2s - loss: 0.0142 - rec: 0.9812 - prec: 0.9930 - auc: 0.9957 - acc: 0.9971\n",
      "Epoch 8/30\n",
      "141/141 - 2s - loss: 0.0135 - rec: 0.9782 - prec: 0.9950 - auc: 0.9961 - acc: 0.9970\n",
      "Epoch 9/30\n",
      "141/141 - 2s - loss: 0.0137 - rec: 0.9821 - prec: 0.9861 - auc: 0.9977 - acc: 0.9964\n",
      "Epoch 10/30\n",
      "141/141 - 2s - loss: 0.0132 - rec: 0.9821 - prec: 0.9910 - auc: 0.9976 - acc: 0.9970\n",
      "Epoch 11/30\n",
      "141/141 - 2s - loss: 0.0142 - rec: 0.9812 - prec: 0.9940 - auc: 0.9962 - acc: 0.9972\n",
      "Epoch 12/30\n",
      "141/141 - 2s - loss: 0.0130 - rec: 0.9821 - prec: 0.9890 - auc: 0.9987 - acc: 0.9968\n",
      "Epoch 13/30\n",
      "141/141 - 2s - loss: 0.0125 - rec: 0.9831 - prec: 0.9930 - auc: 0.9958 - acc: 0.9973\n",
      "Epoch 14/30\n",
      "141/141 - 2s - loss: 0.0125 - rec: 0.9792 - prec: 0.9980 - auc: 0.9964 - acc: 0.9974\n",
      "Epoch 15/30\n",
      "141/141 - 2s - loss: 0.0133 - rec: 0.9821 - prec: 0.9900 - auc: 0.9962 - acc: 0.9969\n",
      "Epoch 16/30\n",
      "141/141 - 2s - loss: 0.0134 - rec: 0.9752 - prec: 0.9919 - auc: 0.9978 - acc: 0.9963\n",
      "Epoch 17/30\n",
      "141/141 - 2s - loss: 0.0166 - rec: 0.9742 - prec: 0.9889 - auc: 0.9952 - acc: 0.9959\n",
      "Epoch 18/30\n",
      "141/141 - 2s - loss: 0.0136 - rec: 0.9821 - prec: 0.9890 - auc: 0.9958 - acc: 0.9968\n",
      "Epoch 19/30\n",
      "141/141 - 2s - loss: 0.0136 - rec: 0.9792 - prec: 0.9910 - auc: 0.9993 - acc: 0.9967\n",
      "Epoch 20/30\n",
      "141/141 - 2s - loss: 0.0126 - rec: 0.9812 - prec: 0.9960 - auc: 0.9969 - acc: 0.9974\n",
      "Epoch 21/30\n",
      "141/141 - 2s - loss: 0.0138 - rec: 0.9812 - prec: 0.9880 - auc: 0.9958 - acc: 0.9966\n",
      "Epoch 22/30\n",
      "141/141 - 2s - loss: 0.0146 - rec: 0.9802 - prec: 0.9850 - auc: 0.9968 - acc: 0.9961\n",
      "Epoch 23/30\n",
      "141/141 - 2s - loss: 0.0119 - rec: 0.9802 - prec: 0.9960 - auc: 0.9982 - acc: 0.9973\n",
      "Epoch 24/30\n",
      "141/141 - 2s - loss: 0.0149 - rec: 0.9821 - prec: 0.9880 - auc: 0.9961 - acc: 0.9967\n",
      "Epoch 25/30\n",
      "141/141 - 2s - loss: 0.0125 - rec: 0.9821 - prec: 0.9900 - auc: 0.9968 - acc: 0.9969\n",
      "Epoch 26/30\n",
      "141/141 - 2s - loss: 0.0113 - rec: 0.9812 - prec: 0.9920 - auc: 0.9992 - acc: 0.9970\n",
      "Epoch 27/30\n",
      "141/141 - 2s - loss: 0.0123 - rec: 0.9802 - prec: 0.9890 - auc: 0.9983 - acc: 0.9966\n",
      "Epoch 28/30\n",
      "141/141 - 2s - loss: 0.0127 - rec: 0.9812 - prec: 0.9930 - auc: 0.9968 - acc: 0.9971\n",
      "Epoch 29/30\n",
      "141/141 - 2s - loss: 0.0125 - rec: 0.9802 - prec: 0.9920 - auc: 0.9978 - acc: 0.9969\n",
      "Epoch 30/30\n",
      "141/141 - 2s - loss: 0.0131 - rec: 0.9802 - prec: 0.9910 - auc: 0.9968 - acc: 0.9968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2926d991508>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(\n",
    "    train_dataset,\n",
    "    epochs=30,\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "39/39 - 1s - loss: 0.0482 - rec: 0.8785 - prec: 0.9961 - auc: 0.9996 - acc: 0.9853\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.04815615341067314,\n",
       " 0.8784722089767456,\n",
       " 0.9960629940032959,\n",
       " 0.999626874923706,\n",
       " 0.9852880835533142]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.evaluate(validation_dataset, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('models/conv/Lada/{}.h5'.format(model.name))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(validation_dataset, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tested_model = tf.keras.models.load_model('models/conv/Mira/MiraConvV2.2.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"MiraConvV2.2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "reshape_10 (Reshape)         (None, 4410, 10)          0         \n",
      "_________________________________________________________________\n",
      "conv1d_21 (Conv1D)           (None, 441, 10)           1000      \n",
      "_________________________________________________________________\n",
      "dropout_17 (Dropout)         (None, 441, 10)           0         \n",
      "_________________________________________________________________\n",
      "re_lu_17 (ReLU)              (None, 441, 10)           0         \n",
      "_________________________________________________________________\n",
      "conv1d_22 (Conv1D)           (None, 21, 10)            2100      \n",
      "_________________________________________________________________\n",
      "dropout_18 (Dropout)         (None, 21, 10)            0         \n",
      "_________________________________________________________________\n",
      "re_lu_18 (ReLU)              (None, 21, 10)            0         \n",
      "_________________________________________________________________\n",
      "conv1d_23 (Conv1D)           (None, 1, 10)             2100      \n",
      "_________________________________________________________________\n",
      "dropout_19 (Dropout)         (None, 1, 10)             0         \n",
      "_________________________________________________________________\n",
      "re_lu_19 (ReLU)              (None, 1, 10)             0         \n",
      "_________________________________________________________________\n",
      "gru_4 (GRU)                  (None, 10)                660       \n",
      "_________________________________________________________________\n",
      "dense_4 (Dense)              (None, 1)                 11        \n",
      "=================================================================\n",
      "Total params: 5,871\n",
      "Trainable params: 5,871\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "tested_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "157/157 [==============================] - 2s 13ms/step - loss: 0.0188 - rec: 1.0000 - prec: 0.9712 - auc: 0.9989 - acc: 0.9968\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.018816368654370308,\n",
       " 1.0,\n",
       " 0.971222996711731,\n",
       " 0.9989398121833801,\n",
       " 0.9968000054359436]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tested_model.evaluate(train_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/23 [==============================] - 0s 14ms/step - loss: 0.0161 - rec: 1.0000 - prec: 0.9730 - auc: 0.9996 - acc: 0.9965\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.016146354377269745,\n",
       " 1.0,\n",
       " 0.9729729890823364,\n",
       " 0.9995825886726379,\n",
       " 0.9964563846588135]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tested_model.evaluate(validation_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(None, 44100, 1)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tested_model.input_shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "audiorec",
   "language": "python",
   "name": "audiorec"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
